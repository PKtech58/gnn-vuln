import json
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.data import Data, Batch
from torch_geometric.loader import DataLoader
from torch_geometric.nn import GCNConv, GATConv, global_mean_pool, global_max_pool
import networkx as nx
import numpy as np
from collections import defaultdict, Counter
import re
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
import os
import traceback

class GraphBuilder:
    """å¤šå±¤ã‚°ãƒ©ãƒ•æ§‹ç¯‰ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, build_cfg=True, build_ddg=True, build_cpg=False):
        self.build_cfg = build_cfg
        self.build_ddg = build_ddg  
        self.build_cpg = build_cpg

    @staticmethod
    def safe_float(value, default=0.0):
        """Noneå€¤ã‚„ã‚¨ãƒ©ãƒ¼å€¤ã‚’å®‰å…¨ã«floatã«å¤‰æ›"""
        if value is None:
            return default
        try:
            return float(value)
        except (ValueError, TypeError):
            return default
    
    @staticmethod
    def safe_normalize(value, max_val=100.0, default=0.0):
        """å®‰å…¨ãªæ­£è¦åŒ–"""
        safe_val = GraphBuilder.safe_float(value, default)
        return safe_val / max_val

    def build_function_graph(self, instructions):
        """é–¢æ•°ãƒ¬ãƒ™ãƒ«ã®ãƒãƒ«ãƒãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰"""
        
        # ãƒãƒ¼ãƒ‰æƒ…å ±æ§‹ç¯‰
        nodes = []
        node_labels = []
        node_metadata = []
        
        for i, inst in enumerate(instructions):
            # ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡
            feature_vector = self._vectorize_instruction_features(inst)
            nodes.append(feature_vector)
            
            # ãƒ©ãƒ™ãƒ«
            label = 1 if inst.get('is_vulnerable', False) else 0
            node_labels.append(label)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
            metadata = {
                'instruction_type': inst['type'],
                'ir_line': inst.get('ir_line_index', 0),
                'source_line': inst.get('source_line'),
                'is_vulnerable': inst.get('is_vulnerable', False),
                'cwe_id': inst.get('vulnerability_info', {}).get('cwe_id') if inst.get('is_vulnerable') else None
            }
            node_metadata.append(metadata)
        
        # ã‚¨ãƒƒã‚¸æ§‹ç¯‰
        edge_index = []
        edge_attr = []
        
        if self.build_cfg:
            cfg_edges, cfg_attrs = self._build_control_flow_edges(instructions)
            edge_index.extend(cfg_edges)
            edge_attr.extend(cfg_attrs)
        
        if self.build_ddg:
            ddg_edges, ddg_attrs = self._build_data_dependency_edges(instructions)
            edge_index.extend(ddg_edges)
            edge_attr.extend(ddg_attrs)
        
        return {
            'nodes': torch.tensor(nodes, dtype=torch.float),
            'labels': torch.tensor(node_labels, dtype=torch.long),
            'edge_index': torch.tensor(edge_index, dtype=torch.long).t().contiguous() if edge_index else torch.empty((2, 0), dtype=torch.long),
            'edge_attr': torch.tensor(edge_attr, dtype=torch.float) if edge_attr else torch.empty((0, 3), dtype=torch.float),
            'metadata': node_metadata
        }
    
    def _vectorize_instruction_features(self, inst):
        """å‘½ä»¤ã‚’ç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ï¼ˆå®‰å…¨ç‰ˆï¼‰"""
        features = inst.get('universal_features', {})
        vector = []
        
        # å‘½ä»¤ã‚¿ã‚¤ãƒ—ï¼ˆone-hot encodingï¼‰
        inst_types = ['alloca', 'load', 'store', 'getelementptr', 'call', 'ret', 'br', 'add', 'sub', 'mul', 'icmp']
        inst_type_vec = [1.0 if inst['type'] == t else 0.0 for t in inst_types]
        vector.extend(inst_type_vec)
        
        # ãƒ¡ãƒ¢ãƒªæ“ä½œç‰¹å¾´é‡
        mem_features = features.get('memory_features', {})
        vector.extend([
            float(mem_features.get('is_memory_operation', False)),
            float(mem_features.get('accesses_array', False)),
            float(mem_features.get('array_size_known', False)),
            self.safe_normalize(mem_features.get('array_size'), 100.0),
            float(mem_features.get('access_index_known', False)),
            self.safe_normalize(mem_features.get('access_index'), 100.0),
            float(mem_features.get('index_is_constant', False)),
            float(mem_features.get('potential_bounds_issue', False)),
            float(mem_features.get('pointer_arithmetic', False)),
        ])
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ç‰¹å¾´é‡
        df_features = features.get('dataflow_features', {})
        vector.extend([
            float(df_features.get('produces_value', False)),
            float(df_features.get('consumes_values', False)),
            self.safe_normalize(df_features.get('variable_count'), 10.0),
            float(df_features.get('uses_temporary_vars', False)),
        ])
        
        # åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼ç‰¹å¾´é‡
        cf_features = features.get('controlflow_features', {})
        vector.extend([
            float(cf_features.get('is_control_flow', False)),
            float(cf_features.get('is_conditional', False)),
            self.safe_normalize(cf_features.get('branches_count'), 5.0),
            float(cf_features.get('has_function_call', False)),
            float(cf_features.get('is_return', False)),
        ])
        
        # å‹ç‰¹å¾´é‡
        type_features = features.get('type_features', {})
        vector.extend([
            self.safe_normalize(type_features.get('type_size_bits'), 64.0),
            float(type_features.get('is_pointer', False)),
            self.safe_normalize(type_features.get('pointer_level'), 3.0),
            float(type_features.get('is_array', False)),
            float(type_features.get('is_integer', False)),
            self.safe_normalize(type_features.get('type_complexity'), 5.0),
        ])
        
        # æ–‡è„ˆç‰¹å¾´é‡
        context_features = features.get('context_features', {})
        vector.extend([
            float(context_features.get('is_in_main', False)),
            float(context_features.get('has_source_info', False)),
        ])
        
        # ç®—è¡“æ¼”ç®—ç‰¹å¾´é‡
        arith_features = features.get('arithmetic_features', {})
        vector.extend([
            float(arith_features.get('is_arithmetic', False)),
            float(arith_features.get('is_overflow_prone', False)),
            float(arith_features.get('uses_constants', False)),
            self.safe_normalize(arith_features.get('operand_count'), 5.0),
        ])
        
        return vector
    
    def _build_control_flow_edges(self, instructions):
        """åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼ã‚¨ãƒƒã‚¸ã‚’æ§‹ç¯‰"""
        edges = []
        edge_attrs = []
        
        # é †æ¬¡å®Ÿè¡Œã‚¨ãƒƒã‚¸
        for i in range(len(instructions) - 1):
            curr_inst = instructions[i]
            next_inst = instructions[i + 1]
            
            # é€šå¸¸ã®é †æ¬¡å®Ÿè¡Œ
            edges.append([i, i + 1])
            edge_attrs.append([1.0, 0.0, 0.0])  # [sequential, branch, call]
            
            # åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼å‘½ä»¤ã®ç‰¹åˆ¥å‡¦ç†
            if curr_inst['type'] == 'br':
                # åˆ†å²å‘½ä»¤
                edges.append([i, i + 1])
                edge_attrs.append([0.0, 1.0, 0.0])  # branch edge
            
            elif curr_inst['type'] in ['call', 'invoke']:
                # é–¢æ•°å‘¼ã³å‡ºã—
                edges.append([i, i + 1])
                edge_attrs.append([0.0, 0.0, 1.0])  # call edge
        
        return edges, edge_attrs
    
    def _build_data_dependency_edges(self, instructions):
        """ãƒ‡ãƒ¼ã‚¿ä¾å­˜ã‚¨ãƒƒã‚¸ã‚’æ§‹ç¯‰"""
        edges = []
        edge_attrs = []
        
        # å¤‰æ•°å®šç¾©ã¨ä½¿ç”¨ã®è¿½è·¡
        var_definitions = {}  # variable_name -> instruction_index
        
        for i, inst in enumerate(instructions):
            df_features = inst.get('universal_features', {}).get('dataflow_features', {})
            
            # å¤‰æ•°å®šç¾©
            if df_features.get('produces_value', False):
                details = inst.get('details', {})
                result_var = details.get('result_variable')
                if result_var:
                    var_definitions[result_var] = i
            
            # å¤‰æ•°ä½¿ç”¨
            dependencies = df_features.get('data_dependencies', [])
            for dep_var in dependencies:
                if dep_var in var_definitions:
                    def_index = var_definitions[dep_var]
                    if def_index != i:  # è‡ªå·±å‚ç…§ã‚’é¿ã‘ã‚‹
                        edges.append([def_index, i])
                        edge_attrs.append([1.0, 0.0, 0.0])  # data dependency
        
        return edges, edge_attrs

class VulnerabilityGNN(nn.Module):
    """å¤šå±¤GNNè„†å¼±æ€§æ¤œå‡ºãƒ¢ãƒ‡ãƒ«"""
    
    def __init__(self, input_dim, hidden_dim=128, num_layers=3, dropout=0.5, attention=True):
        super().__init__()
        
        self.num_layers = num_layers
        self.attention = attention
        
        if attention:
            # Graph Attention Networks
            self.convs = nn.ModuleList([
                GATConv(input_dim if i == 0 else hidden_dim, 
                       hidden_dim, heads=4, dropout=dropout, edge_dim=3)
                for i in range(num_layers)
            ])
        else:
            # Graph Convolutional Networks
            self.convs = nn.ModuleList([
                GCNConv(input_dim if i == 0 else hidden_dim, hidden_dim)
                for i in range(num_layers)
            ])
        
        # Batch Normalization
        self.batch_norms = nn.ModuleList([
            nn.BatchNorm1d(hidden_dim) for _ in range(num_layers)
        ])
        
        # ãƒãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«åˆ†é¡å™¨
        self.node_classifier = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim // 2, hidden_dim // 4),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim // 4, 2)  # binary classification
        )
        
        # ã‚°ãƒ©ãƒ•ãƒ¬ãƒ™ãƒ«åˆ†é¡å™¨
        self.graph_classifier = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),  # mean + max pooling
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim // 2, 2)
        )
        
        self.dropout = dropout
        
    def forward(self, x, edge_index, edge_attr=None, batch=None, return_node_embeddings=False):
        # ã‚°ãƒ©ãƒ•ç•³ã¿è¾¼ã¿
        for i, conv in enumerate(self.convs):
            if self.attention and edge_attr is not None:
                x = conv(x, edge_index, edge_attr=edge_attr)
            else:
                x = conv(x, edge_index)
            
            x = self.batch_norms[i](x)
            x = F.relu(x)
            x = F.dropout(x, self.dropout, training=self.training)
        
        node_embeddings = x
        
        # ãƒãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«äºˆæ¸¬
        node_pred = self.node_classifier(node_embeddings)
        
        # ã‚°ãƒ©ãƒ•ãƒ¬ãƒ™ãƒ«äºˆæ¸¬ï¼ˆå¿…è¦ãªå ´åˆï¼‰
        graph_pred = None
        if batch is not None:
            # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ—ãƒ¼ãƒªãƒ³ã‚°
            graph_mean = global_mean_pool(node_embeddings, batch)
            graph_max = global_max_pool(node_embeddings, batch)
            graph_repr = torch.cat([graph_mean, graph_max], dim=1)
            graph_pred = self.graph_classifier(graph_repr)
        
        if return_node_embeddings:
            return node_pred, graph_pred, node_embeddings
        else:
            return node_pred, graph_pred

class VulnerabilityGNNTrainer:
    """GNNè¨“ç·´ãƒ»è©•ä¾¡ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, model=None, device='cuda' if torch.cuda.is_available() else 'cpu'):
        self.device = device
        self.model = None  # åˆæœŸåŒ–æ™‚ã¯None
        self.train_losses = []
        self.val_losses = []
        self.val_accuracies = []
        
        # ãƒ¢ãƒ‡ãƒ«ãŒæä¾›ã•ã‚ŒãŸå ´åˆã®ã¿GPUã«ç§»å‹•
        if model is not None:
            self.set_model(model)
    
    def set_model(self, model):
        """ãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®šã—ã¦ãƒ‡ãƒã‚¤ã‚¹ã«ç§»å‹•"""
        self.model = model.to(self.device)
        return self.model
    
    def prepare_data(self, dataset_path):
        """TEST-IDåˆ¥ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™"""
        print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿ä¸­...")
        
        with open(dataset_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # TEST-ID + ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼ˆé‡è¦ãªå¤‰æ›´ï¼ï¼‰
        test_file_groups = defaultdict(list)
        test_id_mapping = {}
        
        for item in data['dataset']:
            # ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—
            source_file = item.get('source_file', '')
            file_name = os.path.basename(source_file) if source_file else 'unknown'
            
            # TEST-IDæƒ…å ±ã‚’å–å¾—
            test_id = 'unknown'
            if item.get('is_vulnerable'):
                vuln_info = item.get('vulnerability_info', {})
                test_id = vuln_info.get('test_id', 'unknown')
            else:
                # å®‰å…¨ãªå‘½ä»¤ã®å ´åˆã€åŒã˜ãƒ•ã‚¡ã‚¤ãƒ«å†…ã®è„†å¼±æ€§å‘½ä»¤ã‹ã‚‰TEST-IDã‚’æ¨å®š
                for other_item in data['dataset']:
                    if (other_item.get('source_file') == source_file and 
                        other_item.get('is_vulnerable')):
                        vuln_info = other_item.get('vulnerability_info', {})
                        test_id = vuln_info.get('test_id', 'unknown')
                        break
            
            # TEST-ID + ãƒ•ã‚¡ã‚¤ãƒ«åã§ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚­ãƒ¼ã‚’ä½œæˆ
            graph_key = f"TEST-{test_id}_{file_name}"
            test_file_groups[graph_key].append(item)
            test_id_mapping[graph_key] = {
                'test_id': test_id,
                'file_name': file_name,
                'source_file': source_file
            }
        
        print(f"ğŸ“‹ ç™ºè¦‹ã•ã‚ŒãŸã‚°ãƒ©ãƒ•: {len(test_file_groups)} å€‹")
        for graph_key, items in test_file_groups.items():
            vulnerable_count = sum(1 for item in items if item.get('is_vulnerable', False))
            print(f"   {graph_key}: {len(items)}å‘½ä»¤ ({vulnerable_count}è„†å¼±æ€§)")
        
        # ã‚°ãƒ©ãƒ•æ§‹ç¯‰
        graph_builder = GraphBuilder(build_cfg=True, build_ddg=True)
        graphs = []
        
        print(f"ğŸ”§ {len(test_file_groups)} å€‹ã®TEST-IDã‹ã‚‰ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰ä¸­...")
        
        for graph_key, instructions in test_file_groups.items():
            if len(instructions) < 2:  # æœ€å°é™ã®å‘½ä»¤æ•°
                print(f"   âš ï¸  {graph_key}: å‘½ä»¤æ•°ãŒå°‘ãªã™ãã‚‹ãŸã‚ã‚¹ã‚­ãƒƒãƒ— ({len(instructions)})")
                continue
            
            print(f"   ğŸ”§ {graph_key}: {len(instructions)}å‘½ä»¤ã‹ã‚‰ã‚°ãƒ©ãƒ•æ§‹ç¯‰ä¸­...")
            
            try:
                graph_data = graph_builder.build_function_graph(instructions)
                
                # PyTorch Geometric Data ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
                pyg_data = Data(
                    x=graph_data['nodes'],
                    y=graph_data['labels'],
                    edge_index=graph_data['edge_index'],
                    edge_attr=graph_data['edge_attr'],
                )
                
                # TEST-IDæƒ…å ±ã‚’è¿½åŠ 
                mapping_info = test_id_mapping[graph_key]
                pyg_data.test_id = mapping_info['test_id']
                pyg_data.file_name = mapping_info['file_name']
                pyg_data.source_file = mapping_info['source_file']
                pyg_data.graph_key = graph_key
                
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                pyg_data.metadata = graph_data['metadata']
                pyg_data.num_vulnerable = sum(graph_data['labels'])
                pyg_data.vulnerability_ratio = pyg_data.num_vulnerable / len(graph_data['labels'])
                
                # è„†å¼±æ€§æƒ…å ±ã®è©³ç´°
                vuln_details = []
                for item in instructions:
                    if item.get('is_vulnerable'):
                        vuln_info = item.get('vulnerability_info', {})
                        vuln_details.append(vuln_info)
                pyg_data.vulnerability_details = vuln_details
                
                graphs.append(pyg_data)
                
            except Exception as e:
                print(f"   âŒ {graph_key}: ã‚°ãƒ©ãƒ•æ§‹ç¯‰ã‚¨ãƒ©ãƒ¼ - {e}")
                continue
        
        print(f"âœ… {len(graphs)} å€‹ã®ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰ã—ã¾ã—ãŸ")
        
        # çµ±è¨ˆæƒ…å ±
        total_nodes = sum(g.x.size(0) for g in graphs)
        total_vulnerable = sum(g.num_vulnerable for g in graphs)
        
        print(f"ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ:")
        print(f"   - ç·ãƒãƒ¼ãƒ‰æ•°: {total_nodes}")
        print(f"   - è„†å¼±æ€§ãƒãƒ¼ãƒ‰æ•°: {total_vulnerable}")
        print(f"   - è„†å¼±æ€§ç‡: {total_vulnerable/total_nodes*100:.2f}%")
        
        # TEST-IDçµ±è¨ˆ
        test_ids = set(g.test_id for g in graphs)
        print(f"   - ãƒ¦ãƒ‹ãƒ¼ã‚¯TEST-IDæ•°: {len(test_ids)}")
        
        # TEST-IDåˆ¥çµ±è¨ˆ
        test_id_stats = defaultdict(list)
        for g in graphs:
            test_id_stats[g.test_id].append(g)
        
        print(f"ğŸ“Š TEST-IDåˆ¥çµ±è¨ˆ:")
        for test_id, graph_list in sorted(test_id_stats.items()):
            total_vuln = sum(g.num_vulnerable for g in graph_list)
            total_nodes = sum(g.x.size(0) for g in graph_list)
            print(f"   TEST-ID {test_id}: {len(graph_list)}ã‚°ãƒ©ãƒ•, {total_nodes}ãƒãƒ¼ãƒ‰, {total_vuln}è„†å¼±æ€§")
        
        return graphs, test_id_stats, data.get('comprehensive_statistics', {})

    def split_data_by_test_id(self, graphs, test_size=0.2, val_size=0.2):
        """TEST-IDå˜ä½ã§ã®å±¤åŒ–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ†å‰²"""
        
        # TEST-IDåˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        test_id_groups = defaultdict(list)
        for g in graphs:
            test_id_groups[g.test_id].append(g)
        
        print(f"ğŸ“Š TEST-IDåˆ¥ãƒ‡ãƒ¼ã‚¿åˆ†å‰²:")
        print(f"   - ç·TEST-IDæ•°: {len(test_id_groups)}")
        
        # è„†å¼±æ€§ã®æœ‰ç„¡ã§TEST-IDã‚’åˆ†é¡
        vulnerable_test_ids = []
        safe_test_ids = []
        
        for test_id, graph_list in test_id_groups.items():
            total_vulnerable = sum(g.num_vulnerable for g in graph_list)
            if total_vulnerable > 0:
                vulnerable_test_ids.append(test_id)
            else:
                safe_test_ids.append(test_id)
        
        print(f"   - è„†å¼±æ€§ã‚ã‚ŠTEST-ID: {len(vulnerable_test_ids)} å€‹")
        print(f"   - è„†å¼±æ€§ãªã—TEST-ID: {len(safe_test_ids)} å€‹")
        
        # TEST-IDå˜ä½ã§åˆ†å‰²
        from sklearn.model_selection import train_test_split
        
        train_test_ids = []
        val_test_ids = []
        test_test_ids = []
        
        # è„†å¼±æ€§ã‚ã‚ŠTEST-IDã®åˆ†å‰²
        if len(vulnerable_test_ids) >= 3:
            vuln_train, vuln_temp = train_test_split(
                vulnerable_test_ids, 
                test_size=test_size + val_size, 
                random_state=42
            )
            if len(vuln_temp) >= 2:
                vuln_val, vuln_test = train_test_split(
                    vuln_temp, 
                    test_size=test_size/(test_size + val_size), 
                    random_state=42
                )
            else:
                vuln_val = vuln_temp[:len(vuln_temp)//2] or vuln_temp
                vuln_test = vuln_temp[len(vuln_temp)//2:] or vuln_temp
        else:
            # å°‘æ•°ã®å ´åˆã¯é‡è¤‡ã‚’è¨±å¯
            vuln_train = vulnerable_test_ids
            vuln_val = vulnerable_test_ids[:max(1, len(vulnerable_test_ids)//2)]
            vuln_test = vulnerable_test_ids[:max(1, len(vulnerable_test_ids)//2)]
        
        # è„†å¼±æ€§ãªã—TEST-IDã®åˆ†å‰²ï¼ˆåŒæ§˜ã®å‡¦ç†ï¼‰
        if len(safe_test_ids) >= 3:
            safe_train, safe_temp = train_test_split(
                safe_test_ids, 
                test_size=test_size + val_size, 
                random_state=42
            )
            if len(safe_temp) >= 2:
                safe_val, safe_test = train_test_split(
                    safe_temp, 
                    test_size=test_size/(test_size + val_size), 
                    random_state=42
                )
            else:
                safe_val = safe_temp[:len(safe_temp)//2] or safe_temp
                safe_test = safe_temp[len(safe_temp)//2:] or safe_temp
        else:
            safe_train = safe_test_ids
            safe_val = safe_test_ids[:max(1, len(safe_test_ids)//2)]
            safe_test = safe_test_ids[:max(1, len(safe_test_ids)//2)]
        
        # TEST-IDãƒªã‚¹ãƒˆã‚’çµåˆ
        train_test_ids = vuln_train + safe_train
        val_test_ids = vuln_val + safe_val  
        test_test_ids = vuln_test + safe_test
        
        # TEST-IDã‹ã‚‰ã‚°ãƒ©ãƒ•ã‚’åé›†
        train_graphs = []
        val_graphs = []
        test_graphs = []
        
        for test_id in train_test_ids:
            train_graphs.extend(test_id_groups[test_id])
        
        for test_id in val_test_ids:
            val_graphs.extend(test_id_groups[test_id])
        
        for test_id in test_test_ids:
            test_graphs.extend(test_id_groups[test_id])
        
        print(f"ğŸ“‹ åˆ†å‰²çµæœ:")
        print(f"   - è¨“ç·´: {len(train_graphs)}ã‚°ãƒ©ãƒ• ({len(train_test_ids)}TEST-ID)")
        print(f"   - æ¤œè¨¼: {len(val_graphs)}ã‚°ãƒ©ãƒ• ({len(val_test_ids)}TEST-ID)")  
        print(f"   - ãƒ†ã‚¹ãƒˆ: {len(test_graphs)}ã‚°ãƒ©ãƒ• ({len(test_test_ids)}TEST-ID)")
        
        print(f"   - è¨“ç·´TEST-ID: {sorted(train_test_ids)}")
        print(f"   - æ¤œè¨¼TEST-ID: {sorted(val_test_ids)}")
        print(f"   - ãƒ†ã‚¹ãƒˆTEST-ID: {sorted(test_test_ids)}")
        
        return train_graphs, val_graphs, test_graphs

    
    def train(self, train_graphs, val_graphs, epochs=200, batch_size=32, lr=0.001, weight_decay=1e-5):
        """ãƒ¢ãƒ‡ãƒ«è¨“ç·´"""
        if self.model is None:
            raise ValueError("ãƒ¢ãƒ‡ãƒ«ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚set_model()ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
        train_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)
        val_loader = DataLoader(val_graphs, batch_size=batch_size, shuffle=False)
        
        # ã‚¯ãƒ©ã‚¹é‡ã¿è¨ˆç®—
        total_nodes = sum(g.x.size(0) for g in train_graphs)
        total_vulnerable = sum(g.num_vulnerable for g in train_graphs)
        
        class_weights = torch.tensor([
            total_nodes / (2 * (total_nodes - total_vulnerable)),  # safe weight
            total_nodes / (2 * total_vulnerable) if total_vulnerable > 0 else 1.0  # vulnerable weight
        ], dtype=torch.float).to(self.device)
        
        print(f"âš–ï¸ ã‚¯ãƒ©ã‚¹é‡ã¿: safe={class_weights[0]:.3f}, vulnerable={class_weights[1]:.3f}")
        
        # æœ€é©åŒ–è¨­å®š
        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay)
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=20, factor=0.5)
        criterion = nn.CrossEntropyLoss(weight=class_weights)
        
        best_val_acc = 0.0
        patience_counter = 0
        patience = 30
        
        print(f"ğŸš€ è¨“ç·´é–‹å§‹: {epochs} ã‚¨ãƒãƒƒã‚¯")
        
        for epoch in range(epochs):
            # è¨“ç·´
            train_loss = self._train_epoch(train_loader, optimizer, criterion)
            
            # æ¤œè¨¼
            val_loss, val_acc, val_metrics = self._evaluate(val_loader, criterion)
            
            # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼æ›´æ–°
            scheduler.step(val_loss)
            
            # è¨˜éŒ²
            self.train_losses.append(train_loss)
            self.val_losses.append(val_loss)
            self.val_accuracies.append(val_acc)
            
            # Early stopping
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                patience_counter = 0
                # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ä¿å­˜
                torch.save(self.model.state_dict(), 'best_vulnerability_gnn.pth')
            else:
                patience_counter += 1
            
            if patience_counter >= patience:
                print(f"ğŸ›‘ Early stopping at epoch {epoch+1}")
                break
            
            # ãƒ­ã‚°å‡ºåŠ›
            if epoch % 10 == 0 or epoch == epochs - 1:
                print(f"Epoch {epoch+1:3d}: "
                      f"Train Loss: {train_loss:.4f}, "
                      f"Val Loss: {val_loss:.4f}, "
                      f"Val Acc: {val_acc:.4f}, "
                      f"Val F1: {val_metrics['f1']:.4f}")
        
        # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«å¾©å…ƒ
        self.model.load_state_dict(torch.load('best_vulnerability_gnn.pth'))
        print(f"âœ… è¨“ç·´å®Œäº†! ãƒ™ã‚¹ãƒˆæ¤œè¨¼ç²¾åº¦: {best_val_acc:.4f}")
        
        return best_val_acc
    
    def _train_epoch(self, train_loader, optimizer, criterion):
        """1ã‚¨ãƒãƒƒã‚¯è¨“ç·´"""
        
        if self.model is None:
            raise ValueError("ãƒ¢ãƒ‡ãƒ«ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        self.model.train()
        total_loss = 0
        
        for batch in train_loader:
            batch = batch.to(self.device)
            optimizer.zero_grad()
            
            node_pred, graph_pred = self.model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)
            
            loss = criterion(node_pred, batch.y)
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
        
        return total_loss / len(train_loader)
    
    def _evaluate(self, loader, criterion):
        """è©•ä¾¡"""
        
        if self.model is None:
            raise ValueError("ãƒ¢ãƒ‡ãƒ«ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        self.model.eval()
        total_loss = 0
        all_preds = []
        all_labels = []
        
        with torch.no_grad():
            for batch in loader:
                batch = batch.to(self.device)
                node_pred, graph_pred = self.model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)
                
                loss = criterion(node_pred, batch.y)
                total_loss += loss.item()
                
                preds = torch.argmax(node_pred, dim=1)
                all_preds.extend(preds.cpu().numpy())
                all_labels.extend(batch.y.cpu().numpy())
        
        avg_loss = total_loss / len(loader)
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
        accuracy = np.mean(np.array(all_preds) == np.array(all_labels))
        
        from sklearn.metrics import precision_recall_fscore_support
        precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary', zero_division=0)
        
        metrics = {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1': f1
        }
        
        return avg_loss, accuracy, metrics

    def evaluate_test(self, test_graphs):
        """
        è©³ç´°ãªãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’å‡ºåŠ›ã™ã‚‹evaluate_testãƒ¡ã‚½ãƒƒãƒ‰
        ã€ŒNo valid predictions were madeã€ã‚¨ãƒ©ãƒ¼ã®åŸå› ã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã«ä½œæˆ
        """
    
        print("ğŸ” ===== DEBUG EVALUATE_TEST START =====")
    
        # ã‚¹ãƒ†ãƒƒãƒ— 1: åˆæœŸçŠ¶æ…‹ã®ç¢ºèª
        print("\nğŸ“Š Step 1: Initial State Check")
        print(f"   Model exists: {self.model is not None}")
        print(f"   Device: {self.device}")
        print(f"   Model device: {next(self.model.parameters()).device if self.model is not None else 'N/A'}")
        print(f"   Model mode: {'eval' if not self.model.training else 'train'}")
    
        # ã‚¹ãƒ†ãƒƒãƒ— 2: test_graphsã®è©³ç´°åˆ†æ
        print("\nğŸ“ˆ Step 2: Test Graphs Analysis")
        if test_graphs is None:
            print("   âŒ ERROR: test_graphs is None")
            return {"error": "test_graphs is None"}
    
        if len(test_graphs) == 0:
            print("   âŒ ERROR: test_graphs is empty")
            return {"error": "test_graphs is empty"}
    
        print(f"   âœ… Number of test graphs: {len(test_graphs)}")
        print(f"   âœ… First graph type: {type(test_graphs[0])}")
    
        # ã‚µãƒ³ãƒ—ãƒ«ã‚°ãƒ©ãƒ•ã®è©³ç´°åˆ†æ
        sample_graph = test_graphs[0]
        print(f"   Graph attributes: {list(sample_graph.keys()) if hasattr(sample_graph, 'keys') else 'No keys method'}")
    
        if hasattr(sample_graph, 'x'):
            print(f"   Node features shape: {sample_graph.x.shape if sample_graph.x is not None else 'None'}")
            print(f"   Node features dtype: {sample_graph.x.dtype if sample_graph.x is not None else 'None'}")
    
        if hasattr(sample_graph, 'edge_index'):
            print(f"   Edge index shape: {sample_graph.edge_index.shape if sample_graph.edge_index is not None else 'None'}")
    
        if hasattr(sample_graph, 'y'):
            print(f"   Label: {sample_graph.y}")
            print(f"   Label type: {type(sample_graph.y)}")
    
        # ã‚¹ãƒ†ãƒƒãƒ— 3: ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ä½œæˆã¨æ¤œè¨¼
        print("\nğŸ”„ Step 3: DataLoader Creation")
        try:
            test_loader = DataLoader(test_graphs, batch_size=32, shuffle=False)
            print(f"   âœ… DataLoader created successfully")
            print(f"   Batch size: 32")
            print(f"   Number of batches: {len(test_loader)}")
        except Exception as e:
            print(f"   âŒ ERROR creating DataLoader: {e}")
            traceback.print_exc()
            return {"error": f"DataLoader creation failed: {e}"}
    
        # ã‚¹ãƒ†ãƒƒãƒ— 4: ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™
        print("\nğŸ§  Step 4: Model Preparation")
        try:
            self.model.eval()
            print("   âœ… Model set to evaluation mode")
    
            # ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ç¢ºèª
            total_params = sum(p.numel() for p in self.model.parameters())
            trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
            print(f"   Total parameters: {total_params:,}")
            print(f"   Trainable parameters: {trainable_params:,}")
    
        except Exception as e:
            print(f"   âŒ ERROR preparing model: {e}")
            return {"error": f"Model preparation failed: {e}"}
    
        # ã‚¹ãƒ†ãƒƒãƒ— 5: äºˆæ¸¬å‡¦ç†ã®è©³ç´°ç›£è¦–
        print("\nğŸ¯ Step 5: Prediction Process")
    
        all_predictions = []
        all_labels = []
        batch_count = 0
    
        try:
            with torch.no_grad():
                for batch_idx, batch in enumerate(test_loader):
                    batch_count += 1
                    print(f"\n   Processing batch {batch_idx + 1}/{len(test_loader)}")
    
                    # ãƒãƒƒãƒã®è©³ç´°æƒ…å ±
                    print(f"   Batch size: {batch.batch.max().item() + 1}")
                    print(f"   Batch node features shape: {batch.x.shape}")
                    print(f"   Batch edge index shape: {batch.edge_index.shape}")
                    print(f"   Batch labels shape: {batch.y.shape}")
    
                    # ãƒ‡ãƒã‚¤ã‚¹ã®ç¢ºèª
                    print(f"   Batch device: {batch.x.device}")
    
                    try:
                        # ãƒãƒƒãƒã‚’ãƒ‡ãƒã‚¤ã‚¹ã«ç§»å‹•
                        batch = batch.to(self.device)
                        print(f"   âœ… Batch moved to {self.device}")
    
                        # äºˆæ¸¬å®Ÿè¡Œ
                        print("   ğŸ”„ Running model prediction...")
                        predictions = self.model(batch.x, batch.edge_index)
                        
                        # ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ãŒtupleã®å ´åˆã®å‡¦ç†
                        if isinstance(predictions, tuple):
                            print(f"   Model returned tuple with {len(predictions)} elements")
                            # é€šå¸¸ã€æœ€åˆã®è¦ç´ ãŒäºˆæ¸¬çµæœ
                            predictions = predictions[0]
                            print(f"   Using first element as predictions")
                        
                        print(f"   Raw predictions shape: {predictions.shape}")
                        print(f"   Raw predictions dtype: {predictions.dtype}")
                        print(f"   Raw predictions device: {predictions.device}")
                        
                        # äºˆæ¸¬å€¤ã®çµ±è¨ˆæƒ…å ±
                        print(f"   Predictions min/max/mean: {predictions.min():.4f}/{predictions.max():.4f}/{predictions.mean():.4f}")
    
                        #if nan_count > 0 or inf_count > 0:
                        #    print(f"   âš ï¸  WARNING: Invalid values detected in predictions")
    
                        # äºˆæ¸¬ã‚¯ãƒ©ã‚¹ã®æ±ºå®š
                        if predictions.dim() > 1 and predictions.shape[1] > 1:
                            # å¤šã‚¯ãƒ©ã‚¹åˆ†é¡
                            predicted_classes = torch.argmax(predictions, dim=1)
                            print(f"   Multi-class predictions (argmax): {predicted_classes[:5]}...")
                        else:
                            # ãƒã‚¤ãƒŠãƒªåˆ†é¡
                            predicted_classes = (torch.sigmoid(predictions.squeeze()) > 0.5).long()
                            print(f"   Binary predictions (sigmoid > 0.5): {predicted_classes[:5]}...")
    
                        print(f"   Predicted classes shape: {predicted_classes.shape}")
                        print(f"   Predicted classes unique values: {torch.unique(predicted_classes)}")
    
                        # ãƒ©ãƒ™ãƒ«å‡¦ç†
                        labels = batch.y
                        print(f"   Labels shape: {labels.shape}")
                        print(f"   Labels unique values: {torch.unique(labels)}")
    
                        # CPUç§»å‹•ã¨ä¿å­˜
                        predicted_classes_cpu = predicted_classes.cpu().numpy()
                        labels_cpu = labels.cpu().numpy()
    
                        print(f"   âœ… Converted to CPU numpy arrays")
                        print(f"   CPU predictions shape: {predicted_classes_cpu.shape}")
                        print(f"   CPU labels shape: {labels_cpu.shape}")
    
                        all_predictions.extend(predicted_classes_cpu)
                        all_labels.extend(labels_cpu)
    
                        print(f"   âœ… Batch {batch_idx + 1} processed successfully")
    
                    except Exception as batch_error:
                        print(f"   âŒ ERROR in batch {batch_idx + 1}: {batch_error}")
                        traceback.print_exc()
                        continue
    
            print(f"\nğŸ Step 6: Prediction Summary")
            print(f"   Total batches processed: {batch_count}")
            print(f"   Total predictions collected: {len(all_predictions)}")
            print(f"   Total labels collected: {len(all_labels)}")
    
            # äºˆæ¸¬çµæœã®æ¤œè¨¼
            if len(all_predictions) == 0:
                print("   âŒ CRITICAL ERROR: No predictions were collected")
                return {"error": "No predictions were collected during batch processing"}
    
            # é…åˆ—å¤‰æ›
            all_predictions = np.array(all_predictions)
            all_labels = np.array(all_labels)
    
            print(f"   Final predictions shape: {all_predictions.shape}")
            print(f"   Final labels shape: {all_labels.shape}")
            print(f"   Predictions unique values: {np.unique(all_predictions)}")
            print(f"   Labels unique values: {np.unique(all_labels)}")
    
            # ã‚¹ãƒ†ãƒƒãƒ— 7: ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
            print("\nğŸ“Š Step 7: Metrics Calculation")
    
            try:
                accuracy = accuracy_score(all_labels, all_predictions)
                print(f"   âœ… Accuracy: {accuracy:.4f}")
    
                # ã‚¯ãƒ©ã‚¹åˆ†å¸ƒã®ç¢ºèª
                unique_labels = np.unique(all_labels)
                unique_predictions = np.unique(all_predictions)
    
                print(f"   Label distribution: {dict(zip(*np.unique(all_labels, return_counts=True)))}")
                print(f"   Prediction distribution: {dict(zip(*np.unique(all_predictions, return_counts=True)))}")
    
                # åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆï¼ˆå˜ä¸€ã‚¯ãƒ©ã‚¹å¯¾å¿œï¼‰
                if len(unique_labels) == 1:
                    print("   âš ï¸  Single class in test set - simplified metrics")
                    results = {
                        "accuracy": accuracy,
                        "test_samples": len(all_labels),
                        "single_class_warning": True,
                        "class_distribution": dict(zip(*np.unique(all_labels, return_counts=True)))
                    }
                else:
                    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_predictions, average='weighted')
    
                    print(f"   âœ… Precision: {precision:.4f}")
                    print(f"   âœ… Recall: {recall:.4f}")
                    print(f"   âœ… F1-score: {f1:.4f}")
    
                    # è©³ç´°åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ
                    try:
                        class_report = classification_report(all_labels, all_predictions, output_dict=True)
                        print("   âœ… Classification report generated")
                    except Exception as report_error:
                        print(f"   âš ï¸  Classification report error: {report_error}")
                        class_report = None
    
                    results = {
                        "accuracy": accuracy,
                        "precision": precision,
                        "recall": recall,
                        "f1_score": f1,
                        "test_samples": len(all_labels),
                        "classification_report": class_report
                    }
    
                print("\nğŸ‰ ===== DEBUG EVALUATE_TEST COMPLETED SUCCESSFULLY =====")
                return results
    
            except Exception as metrics_error:
                print(f"   âŒ ERROR calculating metrics: {metrics_error}")
                traceback.print_exc()
                return {"error": f"Metrics calculation failed: {metrics_error}"}
    
        except Exception as e:
            print(f"\nâŒ CRITICAL ERROR in prediction process: {e}")
            traceback.print_exc()
            return {"error": f"Prediction process failed: {e}"}
    

    
    def plot_training_history(self):
        """è¨“ç·´å±¥æ­´ã‚’ãƒ—ãƒ­ãƒƒãƒˆ"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
        
        # Loss
        ax1.plot(self.train_losses, label='Training Loss')
        ax1.plot(self.val_losses, label='Validation Loss')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.set_title('Training and Validation Loss')
        ax1.legend()
        ax1.grid(True)
        
        # Accuracy
        ax2.plot(self.val_accuracies, label='Validation Accuracy')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Accuracy')
        ax2.set_title('Validation Accuracy')
        ax2.legend()
        ax2.grid(True)
        
        plt.tight_layout()
        plt.savefig('training_history.png', dpi=300, bbox_inches='tight')
        plt.show()

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸš€ è„†å¼±æ€§æ¤œå‡ºGNNæ§‹ç¯‰ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯")
    
    # ãƒ‡ãƒ¼ã‚¿æº–å‚™
    trainer = VulnerabilityGNNTrainer()  # ãƒ¢ãƒ‡ãƒ«ã¯Noneã§åˆæœŸåŒ–
    
    # ãƒ‡ãƒ¼ã‚¿æº–å‚™
    graphs, test_id_groups, stats = trainer.prepare_data('universal_vulnerability_dataset.json')
    
    # ç‰¹å¾´é‡æ¬¡å…ƒå–å¾—
    input_dim = graphs[0].x.size(1)
    
    # ãƒ¢ãƒ‡ãƒ«ä½œæˆ
    model = VulnerabilityGNN(
        input_dim=input_dim,
        hidden_dim=64,
        num_layers=2,
        dropout=0.3,
        attention=False
    )
    
    # ãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®šï¼ˆã“ã®è¡Œã‚’å¤‰æ›´ï¼‰
    trainer.set_model(model)
    print(f"ğŸ–¥ï¸  ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {trainer.device}")
    print(f"ğŸ“Š ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model.parameters()):,}")
    
    # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
    train_graphs, val_graphs, test_graphs = trainer.split_data_by_test_id(graphs)
    
    # è¨“ç·´
    best_acc = trainer.train(
        train_graphs=train_graphs,
        val_graphs=val_graphs,
        epochs=200,
        batch_size=16,  # å°ã•ã‚ã®ãƒãƒƒãƒã‚µã‚¤ã‚º
        lr=0.001
    )
    
    # ãƒ†ã‚¹ãƒˆè©•ä¾¡
    test_results = trainer.evaluate_test(test_graphs)
    
    # è¨“ç·´å±¥æ­´ãƒ—ãƒ­ãƒƒãƒˆ
    trainer.plot_training_history()
    
    print(f"\nğŸ‰ GNNæ§‹ç¯‰å®Œäº†!")
    print(f"ğŸ“ˆ æœ€çµ‚çµæœ:")
    print(f"   - ãƒ™ã‚¹ãƒˆæ¤œè¨¼ç²¾åº¦: {best_acc:.4f}")
    if 'accuracy' in test_results:
        print(f"   - ãƒ†ã‚¹ãƒˆç²¾åº¦: {test_results['accuracy']:.4f}")
    elif 'predictions' in test_results and 'labels' in test_results:
        print(f"   - ãƒ†ã‚¹ãƒˆç²¾åº¦: {np.mean(np.array(test_results['predictions']) == np.array(test_results['labels'])):.4f}")
    else:
        print("   - ãƒ†ã‚¹ãƒˆç²¾åº¦: è¨ˆç®—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

if __name__ == "__main__":
    main()