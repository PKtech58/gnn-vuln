#!/usr/bin/env python3
"""
LLVM-IRè„†å¼±æ€§æ¤œå‡ºGNNãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ - æœ€çµ‚ç‰ˆ
äº¤å·®æ¤œè¨¼ãƒ»å€‹åˆ¥CWEæ¤œçŸ¥ãƒ»ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’å¯¾å¿œ

å¼•æ•°ä»•æ§˜:
--data-path: JSONãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
--approach: æ¤œçŸ¥æ–¹å¼ (multi, CWE-416, CWE-119, CWE-476, CWE-190, CWE-78)
--mode: å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ (validate=äº¤å·®æ¤œè¨¼, train=å­¦ç¿’, test=æ¤œçŸ¥)
--output-dir: çµæœå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
"""

import os
import re
import json
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.data import Data, Batch
from torch_geometric.loader import DataLoader
from torch_geometric.nn import GCNConv, GATConv, GraphConv, BatchNorm
import numpy as np
import pandas as pd
from collections import defaultdict
from sklearn.model_selection import train_test_split, KFold
from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, hamming_loss, jaccard_score
import matplotlib.pyplot as plt
import seaborn as sns
import argparse
import traceback
import logging
from datetime import datetime
from pathlib import Path

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def normalize_path(path):
    """ãƒ‘ã‚¹åŒºåˆ‡ã‚Šæ–‡å­—ã‚’çµ±ä¸€ï¼ˆWindows/Linuxå¯¾å¿œï¼‰"""
    if not path:
        return path
    normalized = path.replace('\\\\', '/').replace('\\', '/')
    normalized = re.sub('/+', '/', normalized)
    return normalized


def extract_clean_filename(path):
    """æ­£è¦åŒ–ã•ã‚ŒãŸãƒ‘ã‚¹ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŠ½å‡º"""
    normalized = normalize_path(path)
    return os.path.basename(normalized)


class VulnerabilityDataset:
    """è„†å¼±æ€§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆäº¤å·®æ¤œè¨¼ãƒ»å€‹åˆ¥CWEå¯¾å¿œç‰ˆï¼‰"""
    
    def __init__(self, approach='multi'):
        self.approach = approach
        self.all_target_cwes = ['CWE-416', 'CWE-119', 'CWE-476', 'CWE-190', 'CWE-78']
        
        if approach == 'multi':
            self.target_cwes = self.all_target_cwes
            self.num_classes = 5
        elif approach in self.all_target_cwes:
            self.target_cwes = [approach]
            self.num_classes = 1
        else:
            raise ValueError(f"ç„¡åŠ¹ãªapproach: {approach}")
        
        self.graphs = []
        self.file_groups = defaultdict(list)
        
        logger.info(f"ğŸ¯ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆæœŸåŒ–: approach={approach}, classes={self.num_classes}")
    
    def extract_filename_from_item(self, item):
        """ã‚¢ã‚¤ãƒ†ãƒ ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŠ½å‡ºï¼ˆ7ã¤ã®ãƒ‘ã‚¿ãƒ¼ãƒ³å¯¾å¿œï¼‰"""
        patterns = [
            lambda x: x.get('file_name'),
            lambda x: x.get('file_path'),
            lambda x: x.get('path'),
            lambda x: x.get('source_file'),
            lambda x: x.get('llvm_file_path'),
            lambda x: x.get('metadata', {}).get('file_name') if isinstance(x.get('metadata'), dict) else None,
            lambda x: self._infer_filename_from_url_or_id(x)
        ]
        
        for i, pattern in enumerate(patterns):
            try:
                result = pattern(item)
                if result:
                    filename = extract_clean_filename(result)
                    logger.debug(f"ãƒ‘ã‚¿ãƒ¼ãƒ³{i+1}ã§ãƒ•ã‚¡ã‚¤ãƒ«åæŠ½å‡º: {filename}")
                    return filename
            except Exception as e:
                logger.debug(f"ãƒ‘ã‚¿ãƒ¼ãƒ³{i+1}ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚¢ã‚¤ãƒ†ãƒ ã®ãƒãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
        item_hash = hash(str(item))
        fallback_name = f"item_{abs(item_hash)}.ll"
        logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«åæŠ½å‡ºå¤±æ•—ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä½¿ç”¨: {fallback_name}")
        return fallback_name
    
    def _infer_filename_from_url_or_id(self, item):
        """URL ã¾ãŸã¯IDã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æ¨å®š"""
        test_id = item.get('test_id_from_llvm', item.get('test_id'))
        if test_id:
            return f"test_{test_id}.ll"
        
        for key, value in item.items():
            if isinstance(value, str) and ('.ll' in value or '.c' in value):
                return extract_clean_filename(value)
        
        return None
    
    def load_data(self, json_path):
        """JSONãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆå¼·åŒ–ç‰ˆï¼‰"""
        logger.info(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–‹å§‹: {json_path}")
        
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if isinstance(data, dict) and 'dataset' in data:
                dataset = data['dataset']
            elif isinstance(data, list):
                dataset = data
            else:
                raise ValueError("ç„¡åŠ¹ãªJSONãƒ‡ãƒ¼ã‚¿æ§‹é€ ")
            
            logger.info(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¦ç´ æ•°: {len(dataset)}")
            
            # ãƒ‡ãƒ¼ã‚¿å‡¦ç†
            processed_count = 0
            error_count = 0
            
            for i, item in enumerate(dataset):
                try:
                    if not isinstance(item, dict):
                        error_count += 1
                        continue
                    
                    # ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                    if not self._should_include_item(item):
                        continue
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«åæŠ½å‡ºã¨ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
                    filename = self.extract_filename_from_item(item)
                    self.file_groups[filename].append(self._process_item(item, i))
                    processed_count += 1
                    
                except Exception as e:
                    logger.warning(f"ã‚¢ã‚¤ãƒ†ãƒ {i}å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                    error_count += 1
            
            logger.info(f"âœ… å‡¦ç†å®Œäº†: {processed_count}ä»¶æˆåŠŸ, {error_count}ä»¶ã‚¨ãƒ©ãƒ¼")
            logger.info(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(self.file_groups)}")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°çµ±è¨ˆè¡¨ç¤º
            self._show_file_mapping_stats()
            
            # ã‚°ãƒ©ãƒ•æ§‹ç¯‰
            self._build_graphs()
            
            return len(self.graphs)
            
        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _should_include_item(self, item):
        """ã‚¢ãƒ—ãƒ­ãƒ¼ãƒè¨­å®šã«åŸºã¥ãã‚¢ã‚¤ãƒ†ãƒ åŒ…å«åˆ¤å®š"""
        if self.approach == 'multi':
            return True
        
        vuln_info = item.get('vulnerability_info', {})
        if isinstance(vuln_info, dict):
            cwe_id = vuln_info.get('cwe_id') or vuln_info.get('target_cwe')
            return cwe_id == self.approach
        
        return False
    
    def _process_item(self, item, index):
        """ã‚¢ã‚¤ãƒ†ãƒ å‡¦ç†ï¼ˆãƒ©ãƒ™ãƒ«æŠ½å‡ºå«ã‚€ï¼‰"""
        cwe_labels, trigger_labels = self._extract_labels(item)
        
        processed_item = item.copy()
        processed_item.update({
            'cwe_labels': cwe_labels,
            'trigger_labels': trigger_labels,
            'item_index': index,
        })
        
        return processed_item
    
    def _extract_labels(self, item):
        """CWE-IDãƒ©ãƒ™ãƒ«ã¨is_trigger_lineãƒ©ãƒ™ãƒ«ã®æŠ½å‡º"""
        state = item.get('vulnerability_state', item.get('STATE', 'good'))
        ir_line_index = item.get('ir_line_index', 0)
        
        # åˆæœŸåŒ–: 5ã¤ã®CWE-IDã«å¯¾å¿œ
        cwe_labels = [0.0] * len(self.all_target_cwes)
        trigger_labels = [0.0] * len(self.all_target_cwes)
        
        if state == 'bad':
            vuln_info = item.get('vulnerability_info', {})
            
            if isinstance(vuln_info, dict):
                # CWE-IDå‡¦ç†
                cwe_id = vuln_info.get('cwe_id') or vuln_info.get('target_cwe')
                if cwe_id and cwe_id in self.all_target_cwes:
                    idx = self.all_target_cwes.index(cwe_id)
                    cwe_labels[idx] = 1.0
                
                # is_trigger_lineå‡¦ç†
                is_trigger_line = vuln_info.get('is_trigger_line', False)
                trigger_lines = vuln_info.get('trigger_lines', [])
                
                # ãƒˆãƒªã‚¬ãƒ¼ãƒ©ã‚¤ãƒ³åˆ¤å®š
                if is_trigger_line or (trigger_lines and ir_line_index in trigger_lines):
                    if cwe_id and cwe_id in self.all_target_cwes:
                        idx = self.all_target_cwes.index(cwe_id)
                        trigger_labels[idx] = 1.0
        
        # ã‚¢ãƒ—ãƒ­ãƒ¼ãƒè¨­å®šã«å¿œã˜ãŸèª¿æ•´
        if self.approach != 'multi':
            target_idx = self.all_target_cwes.index(self.approach)
            return [cwe_labels[target_idx]], [trigger_labels[target_idx]]
        
        return cwe_labels, trigger_labels
    
    def _show_file_mapping_stats(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°çµ±è¨ˆè¡¨ç¤º"""
        logger.info(f"ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°çµ±è¨ˆ:")
        logger.info(f"   ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(self.file_groups)}")
        
        # ä¸Šä½5ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¡¨ç¤º
        sorted_files = sorted(self.file_groups.items(), key=lambda x: len(x[1]), reverse=True)
        for filename, items in sorted_files[:5]:
            logger.info(f"   {filename}: {len(items)} items")
        
        if len(sorted_files) > 5:
            logger.info(f"   ... ä»– {len(sorted_files) - 5} ãƒ•ã‚¡ã‚¤ãƒ«")
    
    def _build_graphs(self):
        """ã‚°ãƒ©ãƒ•æ§‹ç¯‰"""
        logger.info(f"ğŸ”§ ã‚°ãƒ©ãƒ•æ§‹ç¯‰é–‹å§‹: {len(self.file_groups)} files")
        
        built_count = 0
        for filename, items in self.file_groups.items():
            try:
                if len(items) < 1:
                    continue
                
                graph = self._build_single_graph(items, filename)
                if graph is not None:
                    self.graphs.append(graph)
                    built_count += 1
                    
            except Exception as e:
                logger.warning(f"ã‚°ãƒ©ãƒ•æ§‹ç¯‰ã‚¨ãƒ©ãƒ¼ ({filename}): {e}")
        
        logger.info(f"âœ… ã‚°ãƒ©ãƒ•æ§‹ç¯‰å®Œäº†: {built_count} graphs")
    
    def _build_single_graph(self, items, filename):
        """å˜ä¸€ã‚°ãƒ©ãƒ•æ§‹ç¯‰"""
        if len(items) == 0:
            return None
        
        # ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã¨ãƒ©ãƒ™ãƒ«
        node_features = []
        node_labels = []
        node_metadata = []
        
        for item in items:
            # ç‰¹å¾´é‡æ§‹ç¯‰ï¼ˆ512æ¬¡å…ƒï¼‰
            feature_vector = [
                item.get('ir_line_index', 0) % 1000,
                len(str(item.get('ir_content', ''))),
                hash(item.get('type', 'unknown')) % 1000,
                1.0 if item.get('is_vulnerable', False) else 0.0
            ]
            
            # 512æ¬¡å…ƒã«æ‹¡å¼µ
            while len(feature_vector) < 512:
                feature_vector.append(0.0)
            
            node_features.append(feature_vector)
            
            # ãƒ©ãƒ™ãƒ«ï¼ˆCWE + ãƒˆãƒªã‚¬ãƒ¼ãƒ©ã‚¤ãƒ³ï¼‰
            cwe_labels = item.get('cwe_labels', [0] * self.num_classes)
            trigger_labels = item.get('trigger_labels', [0] * self.num_classes)
            combined_labels = cwe_labels + trigger_labels
            node_labels.append(combined_labels)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            node_metadata.append({
                'filename': filename,
                'ir_line': item.get('ir_line_index', 0),
                'item_index': item.get('item_index', 0),
            })
        
        # ã‚¨ãƒƒã‚¸æ§‹ç¯‰ï¼ˆé †æ¬¡æ¥ç¶šï¼‰
        edges = []
        edge_attrs = []
        
        for i in range(len(items) - 1):
            edges.append([i, i + 1])
            edge_attrs.append([1.0, 0.0])  # control flow
        
        # PyTorch Geometricãƒ‡ãƒ¼ã‚¿ä½œæˆ
        x = torch.tensor(node_features, dtype=torch.float)
        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous() if edges else torch.empty((2, 0), dtype=torch.long)
        edge_attr = torch.tensor(edge_attrs, dtype=torch.float) if edge_attrs else None
        y = torch.tensor(node_labels, dtype=torch.float)
        
        return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y, metadata=node_metadata)
    
    def get_cross_validation_splits(self, k_folds=5):
        """äº¤å·®æ¤œè¨¼ç”¨åˆ†å‰²"""
        if len(self.file_groups) < k_folds:
            logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«æ•°({len(self.file_groups)})ãŒfoldæ•°({k_folds})ã‚ˆã‚Šå°‘ãªã„ãŸã‚ã€ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã«èª¿æ•´")
            k_folds = len(self.file_groups)
        
        files = list(self.file_groups.keys())
        kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)
        
        splits = []
        for fold, (train_files_idx, val_files_idx) in enumerate(kf.split(files)):
            train_files = [files[i] for i in train_files_idx]
            val_files = [files[i] for i in val_files_idx]
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ã‚°ãƒ©ãƒ•ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
            train_indices = self._get_graph_indices_by_files(train_files)
            val_indices = self._get_graph_indices_by_files(val_files)
            
            splits.append({
                'fold': fold + 1,
                'train_indices': train_indices,
                'val_indices': val_indices,
                'train_files': train_files,
                'val_files': val_files
            })
            
            logger.info(f"Fold {fold + 1}: Train={len(train_indices)}, Val={len(val_indices)}")
        
        return splits
    
    def get_train_test_split(self, test_size=0.2):
        """é€šå¸¸ã®å­¦ç¿’ãƒ»ãƒ†ã‚¹ãƒˆåˆ†å‰²"""
        files = list(self.file_groups.keys())
        
        if len(files) < 2:
            logger.warning("ãƒ•ã‚¡ã‚¤ãƒ«æ•°ãŒå°‘ãªã„ãŸã‚ã€å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å­¦ç¿’ç”¨ã«ä½¿ç”¨")
            return list(range(len(self.graphs))), []
        
        train_files, test_files = train_test_split(files, test_size=test_size, random_state=42)
        
        train_indices = self._get_graph_indices_by_files(train_files)
        test_indices = self._get_graph_indices_by_files(test_files)
        
        logger.info(f"ğŸ“Š åˆ†å‰²çµæœ: Train={len(train_indices)}, Test={len(test_indices)}")
        
        return train_indices, test_indices
    
    def _get_graph_indices_by_files(self, target_files):
        """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ã‚°ãƒ©ãƒ•ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—"""
        indices = []
        
        for i, graph in enumerate(self.graphs):
            if hasattr(graph, 'metadata') and len(graph.metadata) > 0:
                graph_filename = graph.metadata[0].get('filename', '')
                if graph_filename in target_files:
                    indices.append(i)
        
        return indices


class MultiTaskVulnerabilityGNN(nn.Module):
    """ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯è„†å¼±æ€§æ¤œå‡ºGNNï¼ˆCWEåˆ†é¡ + ãƒˆãƒªã‚¬ãƒ¼ãƒ©ã‚¤ãƒ³æ¤œå‡ºï¼‰"""
    
    def __init__(self, input_dim, hidden_dim=128, num_layers=3, num_classes=5, dropout=0.1):
        super(MultiTaskVulnerabilityGNN, self).__init__()
        
        self.num_classes = num_classes
        self.hidden_dim = hidden_dim
        
        # å…±æœ‰GNNå±¤ï¼ˆç‰¹å¾´æŠ½å‡ºï¼‰
        self.convs = nn.ModuleList()
        self.batch_norms = nn.ModuleList()
        
        # å…¥åŠ›å±¤
        self.convs.append(GATConv(input_dim, hidden_dim, heads=4, concat=True))
        self.batch_norms.append(BatchNorm(hidden_dim * 4))
        
        # éš ã‚Œå±¤
        for _ in range(num_layers - 2):
            self.convs.append(GATConv(hidden_dim * 4, hidden_dim, heads=4, concat=True))
            self.batch_norms.append(BatchNorm(hidden_dim * 4))
        
        # å‡ºåŠ›å±¤ï¼ˆç‰¹å¾´æŠ½å‡ºå®Œäº†ï¼‰
        self.convs.append(GATConv(hidden_dim * 4, hidden_dim * 4, heads=1, concat=False))
        self.batch_norms.append(BatchNorm(hidden_dim * 4))
        
        final_hidden_dim = hidden_dim * 4
        
        # ã‚¿ã‚¹ã‚¯å›ºæœ‰ã®åˆ†é¡å™¨
        # 1. CWEåˆ†é¡å™¨
        self.cwe_classifiers = nn.ModuleList([
            nn.Sequential(
                nn.Linear(final_hidden_dim, final_hidden_dim // 2),
                nn.ReLU(),
                nn.Dropout(dropout),
                nn.Linear(final_hidden_dim // 2, 1)
            ) for _ in range(num_classes)
        ])
        
        # 2. is_trigger_lineåˆ†é¡å™¨
        self.trigger_classifiers = nn.ModuleList([
            nn.Sequential(
                nn.Linear(final_hidden_dim, final_hidden_dim // 2),
                nn.ReLU(),
                nn.Dropout(dropout),
                nn.Linear(final_hidden_dim // 2, 1)
            ) for _ in range(num_classes)
        ])
        
        self.dropout = dropout
    
    def forward(self, x, edge_index, edge_attr=None, batch=None):
        # å…±æœ‰ç‰¹å¾´æŠ½å‡º
        for i, conv in enumerate(self.convs):
            x = conv(x, edge_index, edge_attr)
            x = self.batch_norms[i](x)
            if i < len(self.convs) - 1:
                x = F.relu(x)
                x = F.dropout(x, p=self.dropout, training=self.training)
        
        # ã‚¿ã‚¹ã‚¯å›ºæœ‰ã®äºˆæ¸¬
        # 1. CWEåˆ†é¡
        cwe_outputs = []
        for classifier in self.cwe_classifiers:
            cwe_outputs.append(classifier(x))
        cwe_predictions = torch.cat(cwe_outputs, dim=1)
        
        # 2. is_trigger_lineäºˆæ¸¬
        trigger_outputs = []
        for classifier in self.trigger_classifiers:
            trigger_outputs.append(classifier(x))
        trigger_predictions = torch.cat(trigger_outputs, dim=1)
        
        return cwe_predictions, trigger_predictions


class VulnerabilityTrainer:
    """è„†å¼±æ€§æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ï¼ˆäº¤å·®æ¤œè¨¼å¯¾å¿œï¼‰"""
    
    def __init__(self, approach='multi', device='cpu'):
        self.approach = approach
        self.device = device
        self.all_target_cwes = ['CWE-416', 'CWE-119', 'CWE-476', 'CWE-190', 'CWE-78']
        
        if approach == 'multi':
            self.target_cwes = self.all_target_cwes
            self.num_classes = 5
        elif approach in self.all_target_cwes:
            self.target_cwes = [approach]
            self.num_classes = 1
        else:
            raise ValueError(f"ç„¡åŠ¹ãªapproach: {approach}")
        
        self.model = None
        self.training_history = []
        
        logger.info(f"ğŸš€ ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼åˆæœŸåŒ–: approach={approach}, device={device}")
    
    def setup_model(self, input_dim=512, **model_kwargs):
        """ãƒ¢ãƒ‡ãƒ«ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        self.model = MultiTaskVulnerabilityGNN(
            input_dim=input_dim,
            num_classes=self.num_classes,
            **model_kwargs
        ).to(self.device)
        
        logger.info(f"ğŸ”§ ãƒ¢ãƒ‡ãƒ«æ§‹æˆ: {self.num_classes}ã‚¯ãƒ©ã‚¹, ãƒ‡ãƒã‚¤ã‚¹: {self.device}")
        return self.model
    
    def cross_validate(self, dataset, k_folds=5, epochs=50, batch_size=16, learning_rate=0.001):
        """äº¤å·®æ¤œè¨¼å®Ÿè¡Œ"""
        logger.info(f"ğŸ”„ äº¤å·®æ¤œè¨¼é–‹å§‹: {k_folds}-fold")
        
        cv_splits = dataset.get_cross_validation_splits(k_folds)
        fold_results = []
        
        for split in cv_splits:
            logger.info(f"ğŸ“Š Fold {split['fold']} / {k_folds}")
            
            # è¨“ç·´ãƒ»æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿æº–å‚™
            train_graphs = [dataset.graphs[i] for i in split['train_indices']]
            val_graphs = [dataset.graphs[i] for i in split['val_indices']]
            
            if len(train_graphs) == 0 or len(val_graphs) == 0:
                logger.warning(f"Fold {split['fold']}: ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã«ã‚ˆã‚Šã‚¹ã‚­ãƒƒãƒ—")
                continue
            
            # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
            self.setup_model()
            
            # å­¦ç¿’å®Ÿè¡Œ
            fold_history = self._train_single_fold(
                train_graphs, val_graphs, epochs, batch_size, learning_rate
            )
            
            # çµæœä¿å­˜
            fold_result = {
                'fold': split['fold'],
                'train_files': split['train_files'],
                'val_files': split['val_files'],
                'final_val_acc': fold_history['val_accuracies'][-1] if fold_history['val_accuracies'] else 0.0,
                'final_val_loss': fold_history['val_losses'][-1] if fold_history['val_losses'] else 0.0,
                'history': fold_history
            }
            fold_results.append(fold_result)
        
        # äº¤å·®æ¤œè¨¼çµæœã®çµ±è¨ˆ
        cv_summary = self._summarize_cross_validation(fold_results)
        
        return cv_summary, fold_results
    
    def _train_single_fold(self, train_graphs, val_graphs, epochs, batch_size, learning_rate):
        """å˜ä¸€foldå­¦ç¿’"""
        # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
        train_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)
        val_loader = DataLoader(val_graphs, batch_size=batch_size, shuffle=False)
        
        # æå¤±é–¢æ•°ãƒ»æœ€é©åŒ–å™¨
        cwe_criterion = nn.BCEWithLogitsLoss()
        trigger_criterion = nn.BCEWithLogitsLoss()
        optimizer = torch.optim.Adam(self.model.parameters(), lr=learning_rate, weight_decay=1e-5)
        
        # å­¦ç¿’å±¥æ­´
        train_losses = []
        val_losses = []
        val_accuracies = []
        
        for epoch in range(epochs):
            # è¨“ç·´
            train_loss = self._train_epoch(train_loader, optimizer, cwe_criterion, trigger_criterion)
            
            # æ¤œè¨¼
            val_loss, val_acc = self._evaluate(val_loader, cwe_criterion, trigger_criterion)
            
            # å±¥æ­´ä¿å­˜
            train_losses.append(train_loss)
            val_losses.append(val_loss)
            val_accuracies.append(val_acc)
            
            # ãƒ­ã‚°å‡ºåŠ›
            if (epoch + 1) % 10 == 0:
                logger.info(f"  Epoch {epoch+1}/{epochs}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}")
        
        return {
            'train_losses': train_losses,
            'val_losses': val_losses,
            'val_accuracies': val_accuracies
        }
    
    def _train_epoch(self, train_loader, optimizer, cwe_criterion, trigger_criterion):
        """1ã‚¨ãƒãƒƒã‚¯å­¦ç¿’"""
        self.model.train()
        total_loss = 0
        
        for batch in train_loader:
            batch = batch.to(self.device)
            optimizer.zero_grad()
            
            # äºˆæ¸¬
            cwe_pred, trigger_pred = self.model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)
            
            # ãƒ©ãƒ™ãƒ«åˆ†é›¢
            batch_labels = batch.y
            cwe_labels = batch_labels[:, :self.num_classes]
            trigger_labels = batch_labels[:, self.num_classes:self.num_classes*2]
            
            # æå¤±è¨ˆç®—
            cwe_loss = cwe_criterion(cwe_pred, cwe_labels)
            trigger_loss = trigger_criterion(trigger_pred, trigger_labels)
            total_loss_batch = cwe_loss + trigger_loss
            
            # é€†ä¼æ’­
            total_loss_batch.backward()
            optimizer.step()
            
            total_loss += total_loss_batch.item()
        
        return total_loss / len(train_loader)
    
    def _evaluate(self, loader, cwe_criterion, trigger_criterion):
        """è©•ä¾¡"""
        self.model.eval()
        total_loss = 0
        correct_predictions = 0
        total_predictions = 0
        
        with torch.no_grad():
            for batch in loader:
                batch = batch.to(self.device)
                
                # äºˆæ¸¬
                cwe_pred, trigger_pred = self.model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)
                
                # ãƒ©ãƒ™ãƒ«åˆ†é›¢
                batch_labels = batch.y
                cwe_labels = batch_labels[:, :self.num_classes]
                trigger_labels = batch_labels[:, self.num_classes:self.num_classes*2]
                
                # æå¤±
                cwe_loss = cwe_criterion(cwe_pred, cwe_labels)
                trigger_loss = trigger_criterion(trigger_pred, trigger_labels)
                total_loss += (cwe_loss + trigger_loss).item()
                
                # ç²¾åº¦è¨ˆç®—
                cwe_preds = (torch.sigmoid(cwe_pred) > 0.5).int()
                trigger_preds = (torch.sigmoid(trigger_pred) > 0.5).int()
                
                cwe_correct = (cwe_preds == cwe_labels.int()).sum().item()
                trigger_correct = (trigger_preds == trigger_labels.int()).sum().item()
                
                correct_predictions += (cwe_correct + trigger_correct)
                total_predictions += (cwe_labels.numel() + trigger_labels.numel())
        
        accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0.0
        return total_loss / len(loader), accuracy
    
    def _summarize_cross_validation(self, fold_results):
        """äº¤å·®æ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼"""
        if not fold_results:
            return {"error": "äº¤å·®æ¤œè¨¼çµæœãŒã‚ã‚Šã¾ã›ã‚“"}
        
        accuracies = [result['final_val_acc'] for result in fold_results]
        losses = [result['final_val_loss'] for result in fold_results]
        
        summary = {
            'num_folds': len(fold_results),
            'mean_accuracy': np.mean(accuracies),
            'std_accuracy': np.std(accuracies),
            'mean_loss': np.mean(losses),
            'std_loss': np.std(losses),
            'accuracies': accuracies,
            'losses': losses,
            'best_fold': max(fold_results, key=lambda x: x['final_val_acc'])['fold'],
            'worst_fold': min(fold_results, key=lambda x: x['final_val_acc'])['fold']
        }
        
        logger.info(f"ğŸ“Š äº¤å·®æ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼:")
        logger.info(f"   å¹³å‡ç²¾åº¦: {summary['mean_accuracy']:.4f} Â± {summary['std_accuracy']:.4f}")
        logger.info(f"   å¹³å‡æå¤±: {summary['mean_loss']:.4f} Â± {summary['std_loss']:.4f}")
        logger.info(f"   æœ€è‰¯Fold: {summary['best_fold']}, æœ€æ‚ªFold: {summary['worst_fold']}")
        
        return summary
    
    def train_model(self, train_graphs, val_graphs, epochs=100, batch_size=32, learning_rate=0.001):
        """é€šå¸¸å­¦ç¿’"""
        if self.model is None:
            self.setup_model()
        
        logger.info(f"ğŸš€ å­¦ç¿’é–‹å§‹: {epochs}ã‚¨ãƒãƒƒã‚¯")
        
        history = self._train_single_fold(train_graphs, val_graphs, epochs, batch_size, learning_rate)
        self.training_history = history
        
        logger.info("âœ… å­¦ç¿’å®Œäº†!")
        return history
    
    def predict(self, test_graphs, confidence_threshold=0.5):
        """äºˆæ¸¬å®Ÿè¡Œ"""
        if self.model is None:
            raise ValueError("ãƒ¢ãƒ‡ãƒ«ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        self.model.eval()
        test_loader = DataLoader(test_graphs, batch_size=1, shuffle=False)
        
        results = []
        
        logger.info(f"ğŸ¯ äºˆæ¸¬é–‹å§‹ ({len(test_graphs)}ã‚°ãƒ©ãƒ•)")
        
        with torch.no_grad():
            for i, batch in enumerate(test_loader):
                batch = batch.to(self.device)
                
                # äºˆæ¸¬
                cwe_pred, trigger_pred = self.model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)
                
                # ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é©ç”¨
                cwe_probs = torch.sigmoid(cwe_pred).cpu().numpy()
                trigger_probs = torch.sigmoid(trigger_pred).cpu().numpy()
                
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—
                metadata = test_graphs[i].metadata if hasattr(test_graphs[i], 'metadata') else [{}]
                
                # å„ãƒãƒ¼ãƒ‰ï¼ˆè¡Œï¼‰ã§ã®äºˆæ¸¬çµæœ
                for node_idx, (cwe_prob, trigger_prob) in enumerate(zip(cwe_probs, trigger_probs)):
                    node_meta = metadata[node_idx] if node_idx < len(metadata) else {}
                    
                    # å„CWEã”ã¨ã®çµæœ
                    for cwe_idx, cwe_id in enumerate(self.target_cwes):
                        cwe_confidence = float(cwe_prob[cwe_idx])
                        trigger_confidence = float(trigger_prob[cwe_idx])
                        
                        # ä¿¡é ¼åº¦ãŒã—ãã„å€¤ã‚’è¶…ãˆã‚‹å ´åˆã®ã¿è¨˜éŒ²
                        if cwe_confidence > confidence_threshold or trigger_confidence > confidence_threshold:
                            result = {
                                'filename': node_meta.get('filename', f'graph_{i}'),
                                'ir_line': node_meta.get('ir_line', node_idx),
                                'cwe_id': cwe_id,
                                'cwe_confidence': cwe_confidence,
                                'is_trigger_line': trigger_confidence > confidence_threshold,
                                'trigger_confidence': trigger_confidence,
                                'combined_score': (cwe_confidence + trigger_confidence) / 2
                            }
                            results.append(result)
        
        # çµæœã‚’ä¿¡é ¼åº¦é †ã«ã‚½ãƒ¼ãƒˆ
        results.sort(key=lambda x: x['combined_score'], reverse=True)
        
        logger.info(f"âœ… äºˆæ¸¬å®Œäº†: {len(results)}ä»¶ã®è„†å¼±æ€§æ¤œå‡º")
        
        return results
    
    def save_model(self, output_dir, model_name="vulnerability_model"):
        """ãƒ¢ãƒ‡ãƒ«ä¿å­˜"""
        if self.model is None:
            logger.warning("ä¿å­˜ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        os.makedirs(output_dir, exist_ok=True)
        
        model_path = os.path.join(output_dir, f"{model_name}_{self.approach}.pth")
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'approach': self.approach,
            'num_classes': self.num_classes,
            'target_cwes': self.target_cwes,
            'training_history': self.training_history
        }, model_path)
        
        logger.info(f"ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ä¿å­˜: {model_path}")
        return model_path


def convert_to_json_serializable(obj):
    """JSON serializable ãªå‹ã«å¤‰æ›"""
    if isinstance(obj, (np.integer, np.floating)):
        return obj.item()
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif hasattr(obj, 'cpu') and hasattr(obj, 'numpy'):  # torch.Tensor
        return obj.cpu().numpy().item() if obj.numel() == 1 else obj.cpu().numpy().tolist()
    elif isinstance(obj, (np.bool_, bool)):
        return bool(obj)
    return obj


def save_results(results, output_dir, filename_prefix="results"):
    """çµæœä¿å­˜"""
    os.makedirs(output_dir, exist_ok=True)
    
    # JSONå¤‰æ›å‡¦ç†
    serializable_results = []
    for result in results:
        serializable_result = {}
        for key, value in result.items():
            serializable_result[key] = convert_to_json_serializable(value)
        serializable_results.append(serializable_result)
    
    # JSONä¿å­˜
    json_file = os.path.join(output_dir, f"{filename_prefix}.json")
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(serializable_results, f, indent=2, ensure_ascii=False)
    
    # CSVä¿å­˜
    if serializable_results:
        csv_file = os.path.join(output_dir, f"{filename_prefix}.csv")
        df = pd.DataFrame(serializable_results)
        df.to_csv(csv_file, index=False, encoding='utf-8')
        
        logger.info(f"ğŸ’¾ çµæœä¿å­˜: {json_file}, {csv_file}")
    
    return json_file


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(
        description='LLVM-IRè„†å¼±æ€§æ¤œå‡ºGNNãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ - æœ€çµ‚ç‰ˆ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # äº¤å·®æ¤œè¨¼
  python script.py --data-path dataset.json --approach CWE-119 --mode validate --output-dir ../result
  
  # å­¦ç¿’
  python script.py --data-path dataset.json --approach multi --mode train --epochs 100
  
  # æ¤œçŸ¥
  python script.py --data-path dataset.json --approach CWE-119 --mode test --confidence-threshold 0.7
        """
    )
    
    # å¿…é ˆå¼•æ•°
    parser.add_argument('--data-path', required=True,
                       help='JSONãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹')
    
    # æ¤œå‡ºæ–¹å¼
    parser.add_argument('--approach',
                       choices=['multi', 'CWE-416', 'CWE-119', 'CWE-476', 'CWE-190', 'CWE-78'],
                       default='multi',
                       help='æ¤œçŸ¥æ–¹å¼: multi(å…¨CWE) ã¾ãŸã¯ å€‹åˆ¥CWE-ID')
    
    # å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰
    parser.add_argument('--mode',
                       choices=['validate', 'train', 'test'],
                       default='train',
                       help='å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: validate(äº¤å·®æ¤œè¨¼), train(å­¦ç¿’), test(æ¤œçŸ¥)')
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    parser.add_argument('--output-dir', default='./output',
                       help='çµæœå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    
    # å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    parser.add_argument('--epochs', type=int, default=50,
                       help='å­¦ç¿’ã‚¨ãƒãƒƒã‚¯æ•°')
    parser.add_argument('--batch-size', type=int, default=16,
                       help='ãƒãƒƒãƒã‚µã‚¤ã‚º')
    parser.add_argument('--learning-rate', type=float, default=0.001,
                       help='å­¦ç¿’ç‡')
    parser.add_argument('--k-folds', type=int, default=5,
                       help='äº¤å·®æ¤œè¨¼ã®foldæ•°')
    
    # äºˆæ¸¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    parser.add_argument('--confidence-threshold', type=float, default=0.5,
                       help='äºˆæ¸¬ä¿¡é ¼åº¦ã—ãã„å€¤')
    
    args = parser.parse_args()
    
    try:
        logger.info(f"ğŸš€ GNNè„†å¼±æ€§æ¤œå‡ºãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯é–‹å§‹")
        logger.info(f"ğŸ“‹ è¨­å®š: mode={args.mode}, approach={args.approach}")
        logger.info(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿: {args.data_path}")
        logger.info(f"ğŸ“ å‡ºåŠ›: {args.output_dir}")
        
        # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
        if not os.path.exists(args.data_path):
            raise FileNotFoundError(f"ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.data_path}")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿
        dataset = VulnerabilityDataset(approach=args.approach)
        num_graphs = dataset.load_data(args.data_path)
        
        if num_graphs == 0:
            raise ValueError("æœ‰åŠ¹ãªã‚°ãƒ©ãƒ•ãŒä½œæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        
        # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        
        # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼åˆæœŸåŒ–
        trainer = VulnerabilityTrainer(approach=args.approach, device=device)
        
        # ãƒ¢ãƒ¼ãƒ‰åˆ¥å®Ÿè¡Œ
        if args.mode == 'validate':
            # äº¤å·®æ¤œè¨¼
            logger.info(f"ğŸ”„ äº¤å·®æ¤œè¨¼å®Ÿè¡Œ: {args.k_folds}-fold")
            cv_summary, fold_results = trainer.cross_validate(
                dataset, 
                k_folds=args.k_folds,
                epochs=args.epochs,
                batch_size=args.batch_size,
                learning_rate=args.learning_rate
            )
            
            # çµæœä¿å­˜
            save_results([cv_summary], args.output_dir, f"cv_summary_{args.approach}")
            save_results(fold_results, args.output_dir, f"cv_detailed_{args.approach}")
            
        elif args.mode == 'train':
            # é€šå¸¸å­¦ç¿’
            train_indices, test_indices = dataset.get_train_test_split()
            
            if len(train_indices) == 0:
                raise ValueError("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            
            train_graphs = [dataset.graphs[i] for i in train_indices]
            test_graphs = [dataset.graphs[i] for i in test_indices] if test_indices else []
            
            logger.info(f"ğŸš€ å­¦ç¿’å®Ÿè¡Œ: Train={len(train_graphs)}, Test={len(test_graphs)}")
            
            history = trainer.train_model(
                train_graphs, test_graphs,
                epochs=args.epochs,
                batch_size=args.batch_size,
                learning_rate=args.learning_rate
            )
            
            # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
            trainer.save_model(args.output_dir)
            
            # å­¦ç¿’å±¥æ­´ä¿å­˜
            save_results([history], args.output_dir, f"training_history_{args.approach}")
            
        elif args.mode == 'test':
            # æ¤œçŸ¥ãƒ¢ãƒ¼ãƒ‰
            logger.info(f"ğŸ¯ æ¤œçŸ¥ãƒ¢ãƒ¼ãƒ‰: {args.approach}")
            
            # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ï¼ˆäº‹å‰å­¦ç¿’ãŒå¿…è¦ï¼‰
            trainer.setup_model()
            
            # äºˆæ¸¬å®Ÿè¡Œ
            results = trainer.predict(dataset.graphs, confidence_threshold=args.confidence_threshold)
            
            # çµæœè¡¨ç¤º
            logger.info(f"ğŸ“Š æ¤œçŸ¥çµæœã‚µãƒãƒªãƒ¼:")
            logger.info(f"   ç·æ¤œå‡ºæ•°: {len(results)}")
            
            cwe_counts = defaultdict(int)
            trigger_count = 0
            
            for result in results:
                cwe_counts[result['cwe_id']] += 1
                if result['is_trigger_line']:
                    trigger_count += 1
            
            logger.info(f"   ãƒˆãƒªã‚¬ãƒ¼ãƒ©ã‚¤ãƒ³æ•°: {trigger_count}")
            for cwe_id, count in cwe_counts.items():
                logger.info(f"   {cwe_id}: {count}ä»¶")
            
            # é«˜ä¿¡é ¼åº¦çµæœè¡¨ç¤º
            logger.info(f"\nğŸ”¥ é«˜ä¿¡é ¼åº¦æ¤œçŸ¥çµæœ Top 10:")
            for i, result in enumerate(results[:10]):
                trigger_mark = "ğŸ¯" if result['is_trigger_line'] else "  "
                logger.info(f"   {i+1:2d}. {trigger_mark} {result['filename']}:{result['ir_line']} "
                          f"- {result['cwe_id']} (ä¿¡é ¼åº¦: {result['combined_score']:.3f})")
            
            # çµæœä¿å­˜
            save_results(results, args.output_dir, f"detection_results_{args.approach}")
        
        logger.info(f"âœ… å‡¦ç†å®Œäº†! çµæœã¯ {args.output_dir} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
        
    except Exception as e:
        logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())