"""
GnnFramework.pyå®Œå…¨äº’æ›ç‰ˆ - STATEå¯¾å¿œç‰ˆ
STATEã«åŸºã¥ã3æ®µéšãƒ©ãƒ™ãƒªãƒ³ã‚°ï¼ˆbad/good/neutralï¼‰å¯¾å¿œ
"""

import json
import os
import sys
import argparse
import re
from pathlib import Path
from collections import defaultdict, Counter
import hashlib

class GnnCompatibleAnalyzer:
    def __init__(self):
        # å…¨LLVM IRå‘½ä»¤ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.instruction_patterns = {
            'alloca': re.compile(r'^\s*(%[\w\d\.]+)\s*=\s*alloca\s+(.*?)(?:\s*!dbg\s*!(\d+))?$'),
            'load': re.compile(r'^\s*(%[\w\d\.]+)\s*=\s*load\s+(.*?)(?:\s*!dbg\s*!(\d+))?$'),
            'store': re.compile(r'^\s*store\s+(.*?)(?:\s*!dbg\s*!(\d+))?$'),
            'getelementptr': re.compile(r'^\s*(%[\w\d\.]+)\s*=\s*getelementptr\s+(.*?)(?:\s*!dbg\s*!(\d+))?$'),
            'call': re.compile(r'^\s*(?:(%[\w\d\.]+)\s*=\s*)?call\s+(.*?)(?:\s*!dbg\s*!(\d+))?$'),
            'invoke': re.compile(r'^\s*(?:(%[\w\d\.]+)\s*=\s*)?invoke\s+(.*?)(?:\s*!dbg\s*!(\d+))?$'),
            'br': re.compile(r'^\s*br\s+(.*?)(?:\s*!dbg\s*!(\d+))?$'),
            'switch': re.compile(r'^\s*switch\s+(.*?)(?:\s*!dbg\s*!(\d+))?$'),
            'ret': re.compile(r'^\s*ret\s+(.*?)(?:\s*!dbg\s*!(\d+))?$'),
            'add': re.compile(r'^\s*(%[\w\d\.]+)\s*=\s*add\s+(.*?)(?:\s*!dbg\s*!(\d+))?$'),
            'sub': re.compile(r'^\s*(%[\w\d\.]+)\s*=\s*sub\s+(.*?)(?:\s*!dbg\s*!(\d+))?$'),
            'mul': re.compile(r'^\s*(%[\w\d\.]+)\s*=\s*mul\s+(.*?)(?:\s*!dbg\s*!(\d+))?$'),
            'icmp': re.compile(r'^\s*(%[\w\d\.]+)\s*=\s*icmp\s+(.*?)(?:\s*!dbg\s*!(\d+))?$'),
            'bitcast': re.compile(r'^\s*(%[\w\d\.]+)\s*=\s*bitcast\s+(.*?)(?:\s*!dbg\s*!(\d+))?$'),
            'trunc': re.compile(r'^\s*(%[\w\d\.]+)\s*=\s*trunc\s+(.*?)(?:\s*!dbg\s*!(\d+))?$'),
            'zext': re.compile(r'^\s*(%[\w\d\.]+)\s*=\s*zext\s+(.*?)(?:\s*!dbg\s*!(\d+))?$'),
            'sext': re.compile(r'^\s*(%[\w\d\.]+)\s*=\s*sext\s+(.*?)(?:\s*!dbg\s*!(\d+))?$'),
        }

        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.debug_patterns = {
            'dilocation': re.compile(
                r'^\s*!(\d+)\s*=\s*(?:distinct\s+)?!DILocation\s*'
                r'\(\s*line:\s*(\d+)(?:\s*,\s*column:\s*(\d+))?(?:\s*,\s*scope:\s*!(\d+))?\s*\)'
            ),
            'difile': re.compile(
                r'^\s*!(\d+)\s*=\s*(?:distinct\s+)?!DIFile\s*'
                r'\(\s*filename:\s*"([^"]+)"\s*,\s*directory:\s*"([^"]*)"\s*(?:,\s*[^)]*)?\s*\)'
            ),
            'disubprogram': re.compile(
                r'^\s*!(\d+)\s*=\s*(?:distinct\s+)?!DISubprogram\s*'
                r'\((?:[^)]*?)(?:file:\s*!(\d+))(?:[^)]*)\)'
            ),
        }

    def load_llvm_path_jsonl(self, jsonl_path):
        """STATEå¯¾å¿œLLVM_PATHå¯¾å¿œJSONLèª­ã¿è¾¼ã¿"""
        vulnerabilities = []
        llvm_path_mapping = {}
        state_stats = Counter()
        cwe_stats = Counter()

        print(f"  ğŸ“– STATEå¯¾å¿œJSONLèª­ã¿è¾¼ã¿: {jsonl_path}")

        try:
            with open(jsonl_path, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if line:
                        try:
                            vuln_data = json.loads(line)
                            vulnerabilities.append(vuln_data)

                            target_cwe = vuln_data.get('TARGET-CWE-ID')
                            test_id = vuln_data.get('TEST-ID')
                            state = vuln_data.get('STATE', 'unknown')  # STATEæƒ…å ±ã‚’å–å¾—

                            state_stats[state] += 1
                            cwe_stats[target_cwe] += 1

                            # LLVM_PATHãƒãƒƒãƒ”ãƒ³ã‚°æ§‹ç¯‰ï¼ˆSTATEæƒ…å ±å«ã‚€ï¼‰
                            for occurrence in vuln_data.get('OCCURRENCES', []):
                                llvm_path = occurrence.get('LLVM_PATH')
                                if llvm_path:
                                    normalized_path = os.path.normpath(llvm_path)
                                    llvm_path_mapping[normalized_path] = {
                                        'vuln_data': vuln_data,
                                        'occurrence': occurrence,
                                        'test_id': test_id,
                                        'state': state,  # STATEæƒ…å ±ã‚’è¿½åŠ 
                                        'trigger_lines': occurrence.get('TRIGGER_LINE', [])
                                    }

                        except json.JSONDecodeError as e:
                            print(f"Warning: JSONãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼ (è¡Œ {line_num}): {e}")

        except FileNotFoundError:
            print(f"Error: JSONLãƒ•ã‚¡ã‚¤ãƒ« '{jsonl_path}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            sys.exit(1)

        print(f"  ğŸ“Š STATEåˆ†å¸ƒ: {dict(state_stats)}")
        print(f"  ğŸ“Š CWEåˆ†å¸ƒ: {dict(cwe_stats)}")
        print(f"  ğŸ”— LLVM_PATHãƒãƒƒãƒ”ãƒ³ã‚°: {len(llvm_path_mapping)} ä»¶")

        return vulnerabilities, llvm_path_mapping

    def parse_llvm_ir_with_mapping(self, ll_path, llvm_path_mapping):
        """LLVM IRè§£æï¼ˆSTATEå¯¾å¿œãƒãƒƒãƒ”ãƒ³ã‚°ï¼‰"""
        print(f"  ğŸ“– è§£æä¸­: {os.path.basename(ll_path)}")

        try:
            with open(ll_path, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.read().splitlines()
        except Exception as e:
            print(f"    âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None

        # LLVMãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°æ¤œç´¢
        current_mapping = self._find_llvm_mapping(ll_path, llvm_path_mapping)

        if current_mapping:
            state = current_mapping.get('state', 'unknown')
            print(f"    âœ… TEST-ID {current_mapping['test_id']} (STATE: {state}) ã«ãƒãƒƒãƒ”ãƒ³ã‚°")
        else:
            print(f"    âš ï¸  ãƒãƒƒãƒ”ãƒ³ã‚°æƒ…å ±ãªã—")

        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±è§£æ
        fileid_map, scope_map, loc_map = self._parse_debug_info(lines)

        # å‘½ä»¤æŠ½å‡º
        instructions = self._extract_instructions(
            lines, fileid_map, scope_map, loc_map, current_mapping, ll_path
        )

        print(f"    âœ… æŠ½å‡ºå‘½ä»¤æ•°: {len(instructions)}")

        return {
            'll_file': ll_path,
            'mapping_info': current_mapping,
            'instructions': instructions,
            'debug_info_available': len(loc_map) > 0
        }
    
    def normalize_path(self, path):
        """ãƒ‘ã‚¹åŒºåˆ‡ã‚Šæ–‡å­—ã‚’çµ±ä¸€ï¼ˆWindows/Linuxå¯¾å¿œï¼‰"""
        if not path:
            return path
        # ãƒãƒƒã‚¯ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚’å‰ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã«çµ±ä¸€
        normalized = path.replace('\\\\', '/').replace('\\', '/')
        # é‡è¤‡ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚’é™¤å»
        normalized = re.sub('/+', '/', normalized)
        return normalized

    def _find_llvm_mapping(self, ll_path, llvm_path_mapping):
        """LLVMãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°æ¤œç´¢"""
        normalized_path = os.path.normpath(ll_path)

        # å®Œå…¨ä¸€è‡´
        if normalized_path in llvm_path_mapping:
            return llvm_path_mapping[normalized_path]

        # ãƒ•ã‚¡ã‚¤ãƒ«åä¸€è‡´
        ll_basename = os.path.basename(ll_path)
        for mapped_path, mapping_info in llvm_path_mapping.items():
            if os.path.basename(mapped_path) == ll_basename:
                return mapping_info

        return None

    def _parse_debug_info(self, lines):
        """ãƒ‡ãƒãƒƒã‚°æƒ…å ±è§£æ"""
        fileid_map = {}
        scope_map = {}
        loc_map = {}

        for line in lines:
            for pattern_name, pattern in self.debug_patterns.items():
                match = pattern.match(line)
                if match:
                    if pattern_name == 'difile':
                        fid = int(match.group(1))
                        fname = match.group(2)
                        dname = match.group(3)
                        fileid_map[fid] = (fname, dname)
                    elif pattern_name == 'disubprogram':
                        scopeid = int(match.group(1))
                        fileid_str = match.group(2)
                        if fileid_str:
                            scope_map[scopeid] = int(fileid_str)
                    elif pattern_name == 'dilocation':
                        lid = int(match.group(1))
                        line_no = int(match.group(2))
                        column = int(match.group(3)) if match.group(3) else 0
                        scopeid_str = match.group(4)
                        scopeid = int(scopeid_str) if scopeid_str else None
                        loc_map[lid] = (line_no, column, scopeid)
                    break

        return fileid_map, scope_map, loc_map

    def _extract_instructions(self, lines, fileid_map, scope_map, loc_map, mapping_info, ll_path):
        """å‘½ä»¤æŠ½å‡ºã¨ãƒ©ãƒ™ãƒªãƒ³ã‚°"""
        instructions = []
        current_function = None

        for idx, line in enumerate(lines):
            # é–¢æ•°å®šç¾©æ¤œå‡º
            if line.strip().startswith('define '):
                func_match = re.search(r'@(\w+)', line)
                if func_match:
                    current_function = func_match.group(1)

            # å‘½ä»¤ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒ
            for inst_type, pattern in self.instruction_patterns.items():
                match = pattern.match(line)
                if match:
                    instruction_data = self._build_instruction_data(
                        inst_type, match, idx, line, current_function,
                        fileid_map, scope_map, loc_map, mapping_info, ll_path
                    )
                    instructions.append(instruction_data)
                    break

        return instructions

    def _build_instruction_data(self, inst_type, match, idx, line, func_name,
                              fileid_map, scope_map, loc_map, mapping_info, ll_path):
        """STATEå¯¾å¿œã®å‘½ä»¤ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰"""

        # ãƒ‡ãƒãƒƒã‚°IDã‚’å–å¾—
        groups = match.groups()
        dbgid_str = groups[-1] if groups and groups[-1] else None

        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±è§£æ±º
        debug_info = self._resolve_debug_info(
            dbgid_str, fileid_map, scope_map, loc_map, mapping_info, ll_path
        )

        # STATEæƒ…å ±ã¨ãƒˆãƒªã‚¬ãƒ¼ãƒ©ã‚¤ãƒ³åˆ¤å®š
        vulnerability_analysis = self._analyze_vulnerability_context(
            debug_info, mapping_info, idx + 1
        )

        # GnnFramework.pyäº’æ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆSTATEå¯¾å¿œæ‹¡å¼µï¼‰
        instruction_data = {
            # åŸºæœ¬æƒ…å ±
            'type': inst_type,
            'ir_line_index': idx + 1,
            'ir_content': line.strip(),
            'containing_function': func_name,

            # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆGnnFramework.pyãŒæœŸå¾…ï¼‰
            'source_file': debug_info['source_file'],
            'source_line': debug_info.get('source_line'),
            'source_column': debug_info.get('source_column'),
            'has_debug_info': debug_info.get('has_debug_info', False),

            # LLVMé–¢é€£æƒ…å ±
            'llvm_file_path':  self.normalize_path(ll_path),
            'test_id_from_llvm': mapping_info['test_id'] if mapping_info else 'unknown',

            # â˜… STATEå¯¾å¿œè„†å¼±æ€§æƒ…å ±ï¼ˆ3æ®µéšãƒ©ãƒ™ãƒªãƒ³ã‚°ï¼‰
            'is_vulnerable': vulnerability_analysis['is_vulnerable'],
            'vulnerability_state': vulnerability_analysis['state'],  # bad/good/neutral
            'code_quality': vulnerability_analysis['code_quality'],  # vulnerable/safe/neutral
            'vulnerability_info': vulnerability_analysis['vuln_info'],

            # CWEã‚«ãƒ†ã‚´ãƒª
            'cwe_category': vulnerability_analysis.get('cwe_category'),

            # è©³ç´°æƒ…å ±
            'details': self._extract_instruction_details(inst_type, match),
        }

        return instruction_data

    def _analyze_vulnerability_context(self, debug_info, mapping_info, ir_line_index):
        """STATEå¯¾å¿œè„†å¼±æ€§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ"""

        if not mapping_info:
            # ãƒãƒƒãƒ”ãƒ³ã‚°æƒ…å ±ãŒãªã„å ´åˆã¯neutral
            return {
                'is_vulnerable': False,
                'state': 'neutral',
                'code_quality': 'neutral',
                'vuln_info': None,
                'cwe_category': None
            }

        state = mapping_info.get('state', 'unknown')
        trigger_lines = mapping_info.get('trigger_lines', [])
        source_line = debug_info.get('source_line')

        # ãƒˆãƒªã‚¬ãƒ¼ãƒ©ã‚¤ãƒ³åˆ¤å®š
        is_trigger_line = source_line in trigger_lines if source_line else False

        # STATEåˆ¥å‡¦ç†
        if state == 'bad':
            # è„†å¼±æ€§ã‚ã‚Šã‚³ãƒ¼ãƒ‰
            is_vulnerable = True
            code_quality = 'vulnerable'
        elif state == 'good':
            # ä¿®æ­£æ¸ˆã¿ã‚³ãƒ¼ãƒ‰ï¼ˆå®‰å…¨ï¼‰
            is_vulnerable = False
            code_quality = 'safe'
        else:
            # ä¸æ˜ãªçŠ¶æ…‹
            is_vulnerable = False
            code_quality = 'neutral'
            state = 'neutral'

        # è©³ç´°è„†å¼±æ€§æƒ…å ±æ§‹ç¯‰
        vuln_info = {
            'state': state,
            'cwe_id': mapping_info['occurrence'].get('CWE-ID') if mapping_info.get('occurrence') else None,
            'target_cwe': mapping_info['vuln_data'].get('TARGET-CWE-ID') if mapping_info.get('vuln_data') else None,
            'trigger_lines': trigger_lines,
            'is_trigger_line': is_trigger_line,
            'test_id': mapping_info.get('test_id'),
            'source_path': mapping_info['occurrence'].get('PATH') if mapping_info.get('occurrence') else None,
            'flaws': mapping_info['vuln_data'].get('FLAWS') if mapping_info.get('vuln_data') else None,
        }

        # CWEã‚«ãƒ†ã‚´ãƒªåˆ†é¡
        cwe_id = vuln_info.get('cwe_id')
        cwe_category = self._categorize_cwe(cwe_id) if cwe_id else None

        return {
            'is_vulnerable': is_vulnerable,
            'state': state,
            'code_quality': code_quality,
            'vuln_info': vuln_info,
            'cwe_category': cwe_category
        }

    def _resolve_debug_info(self, dbgid_str, fileid_map, scope_map, loc_map, mapping_info, ll_path):
        """ãƒ‡ãƒãƒƒã‚°æƒ…å ±è§£æ±º"""

        if dbgid_str:
            try:
                dbgid = int(dbgid_str)
                if dbgid in loc_map:
                    line_no, column, scopeid = loc_map[dbgid]

                    # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±è§£æ±º
                    if scopeid and scopeid in scope_map and scope_map[scopeid] in fileid_map:
                        fileid = scope_map[scopeid]
                        fname, dname = fileid_map[fileid]
                        full_path = os.path.join(dname, fname) if dname else fname

                        return {
                            'source_file': full_path,
                            'source_line': line_no,
                            'source_column': column,
                            'has_debug_info': True,
                        }
            except:
                pass

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒãƒƒãƒ”ãƒ³ã‚°æƒ…å ±ã¾ãŸã¯LLVMãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
        if mapping_info and mapping_info.get('occurrence'):
            source_path = mapping_info['occurrence'].get('PATH')
            if source_path:
                return {
                    'source_file': source_path,
                    'source_line': None,
                    'source_column': None,
                    'has_debug_info': False,
                }

        # æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: LLVMãƒ•ã‚¡ã‚¤ãƒ«è‡ªä½“
        return {
            'source_file': self.normalize_path(ll_path),
            'source_line': None,
            'source_column': None,
            'has_debug_info': False,
        }

    def _extract_instruction_details(self, inst_type, match):
        """å‘½ä»¤è©³ç´°æƒ…å ±æŠ½å‡º"""
        groups = match.groups()

        if inst_type == 'getelementptr' and len(groups) >= 2:
            return {
                'result_variable': groups[0],
                'gep_operation': groups[1],
            }
        elif inst_type == 'alloca' and len(groups) >= 2:
            return {
                'result_variable': groups[0],
                'alloca_type': groups[1],
            }
        elif inst_type in ['call', 'invoke'] and len(groups) >= 2:
            return {
                'result_variable': groups[0],
                'call_operation': groups[1],
            }
        else:
            return {
                'operation_content': groups[1] if len(groups) >= 2 else '',
            }

    def create_vulnerability_labels(self, vulnerabilities, ir_data_list, llvm_path_mapping):
        """STATEå¯¾å¿œè„†å¼±æ€§ãƒ©ãƒ™ãƒ«ä½œæˆ"""
        print("ğŸ¯ STATEå¯¾å¿œè„†å¼±æ€§ãƒ©ãƒ™ãƒªãƒ³ã‚°:")

        # è„†å¼±æ€§ãƒãƒƒãƒ—æ§‹ç¯‰ï¼ˆSTATEæƒ…å ±å«ã‚€ï¼‰
        vulnerability_map = defaultdict(list)

        for vuln in vulnerabilities:
            test_id = vuln.get("TEST-ID")
            target_cwe = vuln.get("TARGET-CWE-ID")
            state = vuln.get("STATE", "unknown")

            for occurrence in vuln.get("OCCURRENCES", []):
                source_path = occurrence.get("PATH")
                trigger_lines = occurrence.get("TRIGGER_LINE", [])
                cwe_id = occurrence.get("CWE-ID")

                if source_path and trigger_lines:
                    for line_num in trigger_lines:
                        vuln_info = {
                            'line': line_num,
                            'cwe_id': cwe_id,
                            'target_cwe': target_cwe,
                            'test_id': test_id,
                            'source_path': source_path,
                            'state': state,  # â˜… STATEæƒ…å ±ã‚’è¿½åŠ 
                            'trigger_lines': trigger_lines,
                            'cwe_category': self._categorize_cwe(cwe_id),
                            'flaws': vuln.get('FLAWS', ''),
                        }

                        # ãƒ‘ã‚¹æ­£è¦åŒ–
                        path_vars = [source_path, os.path.basename(source_path), os.path.normpath(source_path)]
                        for path_var in path_vars:
                            vulnerability_map[path_var].append(vuln_info)

        # å…¨å‘½ä»¤ã«ãƒ©ãƒ™ãƒ«ä»˜ã‘
        all_instructions = []
        match_stats = Counter()
        state_stats = Counter()

        for ir_data in ir_data_list:
            if not ir_data:
                continue

            for instruction in ir_data['instructions']:
                # æ—¢ã«_build_instruction_dataã§STATEå¯¾å¿œãƒ©ãƒ™ãƒªãƒ³ã‚°æ¸ˆã¿
                all_instructions.append(instruction)

                # çµ±è¨ˆåé›†
                state = instruction.get('vulnerability_state', 'neutral')
                state_stats[state] += 1

                test_id = instruction.get('test_id_from_llvm')
                if test_id and test_id != 'unknown':
                    match_stats[f"test_id_{test_id}_{state}"] += 1

        print(f"  âœ… ç·å‘½ä»¤æ•°: {len(all_instructions)}")
        print(f"  ğŸ”´ è„†å¼±æ€§å‘½ä»¤æ•°(bad): {state_stats.get('bad', 0)}")
        print(f"  ğŸŸ¢ å®‰å…¨å‘½ä»¤æ•°(good): {state_stats.get('good', 0)}")
        print(f"  âšª ä¸­æ€§å‘½ä»¤æ•°(neutral): {state_stats.get('neutral', 0)}")
        print(f"  ğŸ“Š STATEåˆ†å¸ƒ: {dict(state_stats)}")

        return all_instructions

    def _categorize_cwe(self, cwe_id):
        """CWEã‚«ãƒ†ã‚´ãƒªåˆ†é¡"""
        categories = {
            'CWE-119': 'memory_corruption',
            'CWE-416': 'memory_management',
            'CWE-476': 'null_pointer',
            'CWE-190': 'integer_overflow',
            'CWE-78': 'command_injection',
            'CWE-120': 'buffer_overflow',
            'CWE-121': 'stack_buffer_overflow',
            'CWE-122': 'heap_buffer_overflow',
            'CWE-125': 'out_of_bounds_read',
            'CWE-787': 'out_of_bounds_write',
        }
        return categories.get(cwe_id, 'other')

def parse_args():
    parser = argparse.ArgumentParser(description="STATEå¯¾å¿œGnnFramework.pyå®Œå…¨äº’æ›ç‰ˆ")
    parser.add_argument("--jsonl", "-j", required=True, help="STATEå¯¾å¿œLLVM_PATHå¯¾å¿œJSONL")
    parser.add_argument("--llvm-dir", "-l", required=True, help="LLVM IRãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--output", "-o", default="state_aware_vulnerability_dataset.json", help="å‡ºåŠ›JSON")
    return parser.parse_args()

def main():
    args = parse_args()

    print("ğŸŒŸ STATEå¯¾å¿œGnnFramework.pyå®Œå…¨äº’æ›ç‰ˆ")
    print(f"ğŸ“ JSONLãƒ•ã‚¡ã‚¤ãƒ«: {args.jsonl}")
    print(f"ğŸ“‚ LLVM IRãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {args.llvm_dir}")
    print(f"ğŸ’¾ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {args.output}")

    analyzer = GnnCompatibleAnalyzer()

    # STATEå¯¾å¿œJSONLèª­ã¿è¾¼ã¿
    print("ğŸ“– STATEå¯¾å¿œLLVM_PATHå¯¾å¿œJSONLèª­ã¿è¾¼ã¿ä¸­...")
    vulnerabilities, llvm_path_mapping = analyzer.load_llvm_path_jsonl(args.jsonl)
    print(f"âœ… {len(vulnerabilities)} ä»¶ã®è„†å¼±æ€§ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿")

    # LLVM IRãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
    print("ğŸ” LLVM IRãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ä¸­...")
    llvm_files = []
    for root, dirs, files in os.walk(args.llvm_dir):
        for file in files:
            if file.endswith('.ll'):
                llvm_files.append(os.path.join(root, file))
    print(f"âœ… {len(llvm_files)} å€‹ã®LLVM IRãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹")

    # LLVM IRè§£æ
    print("ğŸ”¬ LLVM IRè§£æä¸­...")
    ir_data_list = []
    for ll_file in llvm_files:
        ir_data = analyzer.parse_llvm_ir_with_mapping(ll_file, llvm_path_mapping)
        if ir_data:
            ir_data_list.append(ir_data)

    # STATEå¯¾å¿œè„†å¼±æ€§ãƒ©ãƒ™ãƒªãƒ³ã‚°
    print("ğŸ·ï¸ STATEå¯¾å¿œè„†å¼±æ€§ãƒ©ãƒ™ãƒªãƒ³ã‚°ä¸­...")
    labeled_instructions = analyzer.create_vulnerability_labels(
        vulnerabilities, ir_data_list, llvm_path_mapping
    )

    # STATEåˆ¥çµ±è¨ˆè¨ˆç®—
    state_distribution = Counter(inst.get('vulnerability_state', 'neutral') for inst in labeled_instructions)
    quality_distribution = Counter(inst.get('code_quality', 'neutral') for inst in labeled_instructions)
    cwe_by_state = defaultdict(lambda: defaultdict(int))

    for inst in labeled_instructions:
        state = inst.get('vulnerability_state', 'neutral')
        vuln_info = inst.get('vulnerability_info')
        if vuln_info and vuln_info.get('cwe_id'):
            cwe_by_state[state][vuln_info['cwe_id']] += 1

    # STATEå¯¾å¿œGnnFramework.pyäº’æ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ä¿å­˜
    gnn_compatible_data = {
        # GnnFramework.pyãŒæœŸå¾…ã™ã‚‹ãƒ¡ã‚¤ãƒ³ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
        'dataset': labeled_instructions,

        # â˜… STATEå¯¾å¿œçµ±è¨ˆæƒ…å ±
        'metadata': {
            'total_instructions': len(labeled_instructions),
            'vulnerable_instructions_bad': state_distribution.get('bad', 0),
            'safe_instructions_good': state_distribution.get('good', 0),
            'neutral_instructions': state_distribution.get('neutral', 0),
            'framework_version': 'state_aware_gnn_compatible_v1.0',
        },

        # â˜… è©³ç´°STATEçµ±è¨ˆ
        'stats': {
            'state_distribution': dict(state_distribution),
            'code_quality_distribution': dict(quality_distribution),
            'cwe_by_state': {state: dict(cwes) for state, cwes in cwe_by_state.items()},
            'test_id_distribution': dict(Counter(
                inst['test_id_from_llvm'] 
                for inst in labeled_instructions 
                if inst.get('test_id_from_llvm') != 'unknown'
            )),
        }
    }

    print(f"ğŸ’¾ STATEå¯¾å¿œGnnFramework.pyäº’æ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ä¿å­˜: {args.output}")
    with open(args.output, 'w', encoding='utf-8') as f:
        json.dump(gnn_compatible_data, f, indent=2, ensure_ascii=False)

    print("âœ… å‡¦ç†å®Œäº†ï¼")
    print(f"ğŸ“Š ç·å‘½ä»¤æ•°: {gnn_compatible_data['metadata']['total_instructions']}")
    print(f"ğŸ”´ è„†å¼±æ€§å‘½ä»¤æ•°(bad): {gnn_compatible_data['metadata']['vulnerable_instructions_bad']}")
    print(f"ğŸŸ¢ å®‰å…¨å‘½ä»¤æ•°(good): {gnn_compatible_data['metadata']['safe_instructions_good']}")
    print(f"âšª ä¸­æ€§å‘½ä»¤æ•°(neutral): {gnn_compatible_data['metadata']['neutral_instructions']}")

    # â˜… STATEå¯¾å¿œäº’æ›æ€§ç¢ºèª
    print("ğŸ” STATEå¯¾å¿œGnnFramework.pyäº’æ›æ€§ç¢ºèª:")
    print("âœ… data['dataset'] ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å­˜åœ¨")
    print("âœ… å„å‘½ä»¤ã« source_file ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ä¿è¨¼")
    print("âœ… vulnerability_state ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰è¨­å®šæ¸ˆã¿ (bad/good/neutral)")
    print("âœ… code_quality ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰è¨­å®šæ¸ˆã¿ (vulnerable/safe/neutral)")
    print("âœ… STATEåˆ¥çµ±è¨ˆæƒ…å ±å®Œå‚™")

if __name__ == "__main__":
    main()
